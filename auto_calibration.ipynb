{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/ElinaChhabra/Trilateration-in-3d/blob/master/trilateration.py\n",
    "# https://stackoverflow.com/questions/1406375/finding-intersection-points-between-3-spheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                                         \n",
    "from numpy import sqrt, dot, cross                       \n",
    "from numpy.linalg import norm                            \n",
    "\n",
    "# Find the intersection of three spheres                 \n",
    "# P1,P2,P3 are the centers, r1,r2,r3 are the radii       \n",
    "# Implementaton based on Wikipedia Trilateration article.                              \n",
    "def trilaterate(P1,P2,P3,r1,r2,r3):                      \n",
    "    temp1 = P2-P1                                        \n",
    "    e_x = temp1/norm(temp1)                              \n",
    "    temp2 = P3-P1                                        \n",
    "    i = dot(e_x,temp2)                                   \n",
    "    temp3 = temp2 - i*e_x                                \n",
    "    e_y = temp3/norm(temp3)                              \n",
    "    e_z = cross(e_x,e_y)                                 \n",
    "    d = norm(P2-P1)                                      \n",
    "    j = dot(e_y,temp2)                                   \n",
    "    x = (r1*r1 - r2*r2 + d*d) / (2*d)                    \n",
    "    y = (r1*r1 - r3*r3 -2*i*x + i*i + j*j) / (2*j)\n",
    "    temp4 = r1*r1 - x*x - y*y\n",
    "    if abs(temp4) < 1e-6:\n",
    "        raise ArithmeticError(\"Exact intersection found. Algorithm does not work in this case.\")\n",
    "    elif temp4 < 0:                                          \n",
    "        raise ValueError(\"The three spheres do not intersect.\")\n",
    "    z = sqrt(temp4)                                      \n",
    "    p_12_a = P1 + x*e_x + y*e_y + z*e_z                  \n",
    "    p_12_b = P1 + x*e_x + y*e_y - z*e_z                  \n",
    "    return p_12_a, p_12_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 3), (4, 3), (4, 1000))"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.shape, anchors.shape, line_lengths.shape, \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "from collections import defaultdict\n",
    "\n",
    "line_init = np.array([100, 200, 300, 100])\n",
    "# hat_line_lengths = line_lengths - line_init[:, None]\n",
    "\n",
    "measured_points = np.array([\n",
    "                            [50., 50., 10.], [60., 50., 10.], [50., 60., 10.], [40., 50., 10.], [50., 40., 10.],\n",
    "                            [55., 55., 10.], [45., 55., 10.], [45., 45., 10.], [55., 45., 10.],\n",
    "                            [50., 50., 50.], [70., 50., 50.], [50., 70., 50.], [30., 50., 15.], [50., 30., 15.],\n",
    "                            ])\n",
    "################################################################\n",
    "sim_measured_points = simulate_points(5000, 50, np.array([50, 50, 50]))\n",
    "grid_points = np.concatenate([measured_points, sim_measured_points], axis=0)\n",
    "################################################################\n",
    "measured_line_lengths = find_line_lengths(grid_points, anchors)\n",
    "# measured_line_lengths -= line_init[:, None]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distances_to_center(grid_points[0], anchors, measured_line_lengths[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def multilat_to_dist_err(point, anchors, line_lengths):\n",
    "    return ((np.linalg.norm(point - anchors, axis=1) - np.abs(line_lengths))**2).sum()\n",
    "\n",
    "# def distances_to_center(point, anchors, line_lengths):\n",
    "#     # point of size 3 dim\n",
    "#     # line_lengths of number of anchors dim\n",
    "#     return ((np.linalg.norm(point - anchors, axis=1) - line_lengths)**2).sum()\n",
    "\n",
    "def multilaterate_error(anchors, line_lengths):\n",
    "    point = minimize(multilat_to_dist_err,\n",
    "                     x0=np.ones(3)*50,\n",
    "                     args=(anchors, line_lengths))\n",
    "    if point.success:\n",
    "        return multilat_to_dist_err(point.x, anchors, line_lengths)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "# def multilaterate_error_alg(anchors, line_lengths):\n",
    "#     a1, a2, a3, a4 = anchors\n",
    "#     d1, d2, d3, d4 = line_lengths\n",
    "#     x1 = a1 - np.sqrt(-a2**2 + 2*a2*x2 - a3**2 + 2*a3*x3 - a4**2 + 2 a4 x4 + d**2 - x2**2 - x3**2 - x4**2)\n",
    "\n",
    "def multilaterate_errors(x, obs_line_lengths, num_points_grid=None, num_points_torque=None):\n",
    "    anchors = x[:4*3].reshape(4, 3)\n",
    "    line_init = x[4*3:4*3+4]\n",
    "    errors = []\n",
    "    for obs_line_length in obs_line_lengths.T[:num_points_torque]:  # for every data point\n",
    "        multilat_err = multilaterate_error(anchors, obs_line_length + line_init)\n",
    "        # skip if failure\n",
    "        if multilat_err is None:\n",
    "            continue\n",
    "        errors.append(multilat_err)\n",
    "    mean_error = np.array(errors).nanmean()\n",
    "    return mean_error\n",
    "\n",
    "def euclidean_estimate(obs_line_lengths, method, options):\n",
    "    sol = minimize(multilaterate_errors,\n",
    "                   args=(obs_line_lengths,),\n",
    "                   method='BFGS',\n",
    "                   options={'gtol': 1e-3, 'disp': True, 'maxiter': 1e5},\n",
    "                   tol=1e-3,\n",
    "                   x0=np.concatenate([anchors.flatten(), line_lengths[:,0].flatten()])\n",
    "    )\n",
    "    if sol.success:\n",
    "        return sol.x\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 852,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([np.nan, 1, 2, 3], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(multilaterate_errors(np.concatenate([anchors.flatten(), line_init.flatten()]), measured_line_lengths), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact intersection.\n"
     ]
    }
   ],
   "source": [
    "P1 = np.array([0, 0, 0])\n",
    "P2 = np.array([6, 0, 0])\n",
    "P3 = np.array([3, 3, 0])\n",
    "r1 = 3\n",
    "r2 = 3\n",
    "r3 = 3\n",
    "try:\n",
    "    trilaterate(P1,P2,P3,r1,r2,r3)  # fails\n",
    "except ArithmeticError:\n",
    "    print('Exact intersection.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.99995000e+00 5.00000000e-05 1.73203637e-02] [ 2.99995000e+00  5.00000000e-05 -1.73203637e-02]\n",
      "0.034640727474987816\n"
     ]
    }
   ],
   "source": [
    "P1 = np.array([0, 0, 0])\n",
    "P2 = np.array([5.9999, 0, 0])\n",
    "P3 = np.array([3, 3, 0])\n",
    "r1 = 3\n",
    "r2 = 3\n",
    "r3 = 3\n",
    "try:\n",
    "    p1, p2 = trilaterate(P1,P2,P3,r1,r2,r3)  # fails\n",
    "except ArithmeticError:\n",
    "    print('Exact intersection.')\n",
    "print(p1, p2)\n",
    "print(np.linalg.norm(p1-p2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors = np.array(\n",
    "    [\n",
    "        [0, 0, -10],\n",
    "        [100, 0, -10],\n",
    "        [50, 100, -10],\n",
    "        [50, 50, 100]\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[49.10654192, 50.12237093, 48.06493647],\n",
       "       [48.76943602, 45.78532115, 43.20561633],\n",
       "       [46.90599109, 55.26556547, 57.01523976],\n",
       "       [54.09989681, 54.68264465, 51.36214907],\n",
       "       [54.11623779, 50.69270532, 43.18071202],\n",
       "       [45.86980736, 44.64174164, 55.7898519 ],\n",
       "       [57.71702843, 54.84355323, 51.30438641],\n",
       "       [54.00162518, 48.67983039, 51.00746696],\n",
       "       [55.25077438, 43.2781916 , 45.79155213],\n",
       "       [48.56676502, 57.11314158, 55.50336373],\n",
       "       [58.76092392, 49.46563002, 49.45217806],\n",
       "       [47.3464051 , 51.44012346, 59.52181206],\n",
       "       [45.60773059, 52.00692779, 51.83507629],\n",
       "       [46.48125223, 55.10045466, 51.69521405],\n",
       "       [51.62929037, 54.29004762, 48.26518105],\n",
       "       [58.64543499, 54.05077482, 52.34790076],\n",
       "       [49.60861766, 44.7327685 , 45.84576178],\n",
       "       [47.29052566, 44.08822001, 54.97186403],\n",
       "       [56.73895579, 52.62081491, 46.11472843],\n",
       "       [54.59955661, 55.77471539, 48.87366506],\n",
       "       [53.59705586, 42.97413146, 47.4369466 ],\n",
       "       [48.56666599, 53.78818469, 56.03458671],\n",
       "       [43.47261257, 52.29151266, 48.25732361],\n",
       "       [47.8976177 , 46.13570833, 45.57966904],\n",
       "       [47.8552823 , 56.08896785, 56.66306994],\n",
       "       [48.64704042, 51.16966288, 42.6522016 ],\n",
       "       [54.25099272, 49.45411124, 47.91056528],\n",
       "       [44.32632229, 45.43196081, 43.92188405],\n",
       "       [48.08712508, 46.69944973, 51.84731532],\n",
       "       [55.83685736, 53.04200578, 54.02948971],\n",
       "       [48.06031422, 51.49350587, 45.39789067],\n",
       "       [47.55386754, 57.84211261, 52.39829696],\n",
       "       [48.15206259, 51.48555727, 50.14765049],\n",
       "       [46.28869073, 47.03330733, 48.58369543],\n",
       "       [52.43243879, 51.21382198, 56.95662158],\n",
       "       [59.02999547, 48.70233176, 49.19220687],\n",
       "       [45.2508714 , 53.60018244, 47.54112114],\n",
       "       [44.66087861, 45.41949154, 43.01472339],\n",
       "       [41.76762725, 51.83885374, 53.14639536],\n",
       "       [52.71116936, 48.18324489, 47.24467969],\n",
       "       [52.28768739, 47.09217613, 50.78611336],\n",
       "       [55.22663724, 44.5366775 , 50.88801821],\n",
       "       [45.70938253, 58.21322142, 52.09411381],\n",
       "       [48.49417779, 44.40227498, 51.92082066],\n",
       "       [44.71887251, 45.59079016, 43.11289209],\n",
       "       [50.30325927, 58.06682814, 53.26324559],\n",
       "       [55.96211689, 45.52768605, 49.86076604],\n",
       "       [43.71458157, 43.90041077, 48.62770993],\n",
       "       [48.98411587, 51.88907817, 45.64956728],\n",
       "       [53.46260945, 45.36169673, 42.61067126]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def simulate_points(n_points, radius, center=np.array([50, 50, 50])):\n",
    "    def sample(n_points, radius):\n",
    "        oversample_proportion = 1 + (4/3 * np.pi * radius**3) / (2 * radius)**3\n",
    "        points = np.random.rand(int(n_points * oversample_proportion), 3) * 2 * radius\n",
    "        points -= [radius, radius, radius]\n",
    "        accepted_points = points[np.linalg.norm(points, axis=1) < radius]\n",
    "        return accepted_points\n",
    "    points = sample(n_points, radius)[:n_points]\n",
    "    while len(points) < n_points:\n",
    "        new_points = sample(n_points - len(points), radius)\n",
    "        points = np.concatenate([points, new_points], axis=0)\n",
    "    points = points + center\n",
    "    return points[:n_points]\n",
    "\n",
    "points = simulate_points(50, radius=10)\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 91.0782157 ,  85.47275081,  98.71928427,  98.39869816,\n",
       "         91.24968874,  91.78904584, 100.48531482,  94.90949602,\n",
       "         89.65683034,  99.5556742 ,  97.1300994 ,  98.59538899,\n",
       "         92.78126044,  94.88343559,  94.90955809, 101.23257397,\n",
       "         87.06770143,  91.65974076,  95.58829433,  97.76522335,\n",
       "         89.54564873,  98.04313592,  89.54432475,  86.67055425,\n",
       "         99.39851735,  88.07453249,  93.50140587,  83.28538582,\n",
       "         91.20471817, 100.15480303,  89.61194809,  97.4711638 ,\n",
       "         92.66673404,  88.24298419,  99.27338703,  96.74799656,\n",
       "         90.72817392,  82.87391137,  91.75657301,  91.52620289,\n",
       "         92.98724043,  93.49250165,  96.61162336,  90.31852154,\n",
       "         83.06188664,  99.52091572,  93.74347996,  85.29606719,\n",
       "         90.49195755,  87.65738343],\n",
       "       [ 92.05396782,  86.90054044, 101.8052006 ,  94.13991947,\n",
       "         86.6213492 ,  96.18350932,  92.48725755,  90.59518419,\n",
       "         83.59540867, 100.98504474,  87.6474268 , 101.25102326,\n",
       "         97.40028835,  98.52215946,  93.17706876,  92.2981421 ,\n",
       "         87.51606196,  94.56956669,  88.25718585,  92.94152772,\n",
       "         85.43425563,  99.49433804,  96.55911961,  89.06324402,\n",
       "        101.53328909,  89.59751777,  88.83869853,  89.83980762,\n",
       "         93.27848412,  94.14676361,  91.75095856,  99.94925845,\n",
       "         94.63990216,  92.35305145,  96.79213612,  86.91476138,\n",
       "         95.81976447,  89.08372165, 100.3281777 ,  88.51447307,\n",
       "         90.49358764,  87.72411536, 100.95508537,  91.97064627,\n",
       "         89.19362371,  99.21572865,  87.15168763,  92.37154738,\n",
       "         91.60770276,  83.61396402],\n",
       "       [ 76.55137488,  75.9709372 ,  80.63364611,  76.39231106,\n",
       "         72.63842546,  86.08077528,  76.53028816,  79.8228278 ,\n",
       "         79.73475696,  78.30726306,  78.51775476,  84.84329984,\n",
       "         78.39772746,  76.38488198,  74.07351521,  77.93160829,\n",
       "         78.5707908 ,  85.76019769,  73.75000645,  73.77763995,\n",
       "         81.01784574,  80.61112183,  75.58189138,  77.42662035,\n",
       "         79.85451429,  71.82260547,  76.98435803,  76.92484059,\n",
       "         81.66822003,  79.61719461,  73.65845943,  75.34466468,\n",
       "         77.29686854,  79.06512328,  82.88061955,  78.84610922,\n",
       "         74.07076288,  76.27646437,  79.84193897,  77.26111507,\n",
       "         80.61899848,  82.52786585,  74.96814812,  83.23198039,\n",
       "         76.21831623,  75.89941443,  81.15473575,  81.38721502,\n",
       "         73.57015127,  75.9290233 ],\n",
       "       [ 51.94289235,  56.96384662,  43.41645637,  49.03444562,\n",
       "         56.97240333,  44.72478753,  49.5406431 ,  49.17340892,\n",
       "         54.87539668,  45.08438294,  51.30420687,  40.59062971,\n",
       "         48.40640108,  48.70060132,  51.9379494 ,  48.59912432,\n",
       "         54.41119761,  45.4953121 ,  54.36823235,  51.65661026,\n",
       "         53.15238679,  44.15158383,  52.20308781,  54.59784962,\n",
       "         43.81512126,  57.37567945,  52.26545841,  56.54920591,\n",
       "         48.3035585 ,  46.43932083,  54.65696006,  48.30532504,\n",
       "         49.9087017 ,  51.63537022,  43.12913804,  51.62031193,\n",
       "         52.79630202,  57.41784588,  47.60686517,  52.85617145,\n",
       "         49.35276681,  49.69056636,  48.79385551,  48.42736326,\n",
       "         57.3016098 ,  47.42878762,  50.69014907,  52.11356504,\n",
       "         54.39274008,  57.68048695]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_line_lengths(points, anchors):\n",
    "    line_lengths = []\n",
    "    for anchor in anchors:\n",
    "        line_lengths.append(np.linalg.norm(points - anchor, axis=1))\n",
    "    line_lengths = np.array(line_lengths)\n",
    "    return line_lengths\n",
    "line_lengths = find_line_lengths(points, anchors)\n",
    "line_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add noise to anchors and lengths\n",
    "noisy_anchors = anchors * (1 + (np.random.rand(*anchors.shape)-0.5)/10)\n",
    "noisy_line_lengths = line_lengths * (1 + (np.random.rand(*line_lengths.shape)-0.5) * 1/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([52.40658206, 50.40480604, 39.29233448])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "def find_intersections(anchors, line_lengths):\n",
    "    intersections_by_point = []\n",
    "    for point_index in range(line_lengths.shape[1]):\n",
    "        intersections_by_anchor_combo = []\n",
    "        inter_trilat_point_errors = []\n",
    "        for anchor_index in itertools.combinations(range(len(anchors)), 3):\n",
    "            # TODO: generalize to case when there's more than 1 validation anchor (ie len(anchors) > 4)\n",
    "            anchor_subset = anchors[list(anchor_index)]\n",
    "            anchor_val_index = np.setdiff1d(np.arange(line_lengths.shape[0]), anchor_index)\n",
    "            anchor_val = anchors[anchor_val_index]\n",
    "            \n",
    "            try:\n",
    "                intersections_i = trilaterate(*anchor_subset, *line_lengths[anchor_index, point_index])\n",
    "            except ValueError:\n",
    "                intersections_by_anchor_combo.append([np.nan, np.nan, np.nan])\n",
    "                inter_trilat_point_errors.append(np.nan)\n",
    "                continue\n",
    "                # print('Warning: No intersection possible, attempting with added noise.')\n",
    "                # intersections_noisy = []\n",
    "                # intersection_count = 0\n",
    "                # j = 0\n",
    "                # while intersection_count < 20 and j < 1000:\n",
    "                #     try:\n",
    "                #         # add noise, make noise grow slowly\n",
    "                #         line_lengths_noisy = line_lengths * (1 + (np.random.rand(*line_lengths.shape)-0.5) * (j+1)**(1/3)/100)\n",
    "                #         intersections_noisy.append(trilaterate(*anchor_subset, *line_lengths_noisy[anchor_index, i]))\n",
    "                #         intersection_count += 1\n",
    "                #         j += 1\n",
    "                #     except:\n",
    "                #         j += 1\n",
    "                # if intersection_count == 0:\n",
    "                #     raise ValueError('No intersections found.')\n",
    "                # elif intersection_count < 20:\n",
    "                #     print('Warning: low count of random intersections. Convergence might be bad.')\n",
    "                # intersections_i = np.array(intersections_noisy).mean(axis=0)\n",
    "            # tie-brake between points using the 4th anchor\n",
    "            dist0 = np.linalg.norm(anchor_val-intersections_i[0])\n",
    "            dist1 = np.linalg.norm(anchor_val-intersections_i[1])\n",
    "            radius_val = line_lengths[anchor_val_index, point_index]\n",
    "            error_between_single_trilat_points = np.abs(radius_val-dist0) - np.abs(radius_val-dist1)\n",
    "            if error_between_single_trilat_points < 0:\n",
    "                weighted_intersection = intersections_i[0] * 0.9 + intersections_i[1] * 0.1\n",
    "            else:\n",
    "                weighted_intersection = intersections_i[1] * 0.9 + intersections_i[0] * 0.1\n",
    "            inter_trilat_point_errors.append(abs(error_between_single_trilat_points.item()))\n",
    "            intersections_by_anchor_combo.append(weighted_intersection)\n",
    "\n",
    "        nan_filter = ~np.isnan(np.array(intersections_by_anchor_combo)).all(axis=1)\n",
    "        intersections_by_anchor_combo = np.array(intersections_by_anchor_combo)[nan_filter]\n",
    "        inter_trilat_point_errors = np.array(inter_trilat_point_errors)[nan_filter]\n",
    "        point_estimate = np.average(intersections_by_anchor_combo, weights=inter_trilat_point_errors, axis=0)\n",
    "        intersections_by_point.append(np.array(point_estimate))\n",
    "\n",
    "    return np.array(intersections_by_point)\n",
    "\n",
    "estimated_intersections_anchor = find_intersections(noisy_anchors, noisy_line_lengths)\n",
    "\n",
    "estimated_intersections = estimated_intersections_anchor.mean(axis=0)\n",
    "estimated_intersections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 71.41428429,  71.41428429, 100.        ])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_line_lengths([[50,50,0]], anchors).T[0][[0, 1, 3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 50.        , -25.34246576,  34.24657535]),\n",
       " array([ 5.00000000e+01,  5.00000000e+01, -1.42108547e-14]))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trilaterate(np.array([0,0,-10]), [100,0,-10], [50, 50, 100], 71.41428429, 71.41428429, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49.10654192 50.12237093 48.06493647] [ 49.10654192  50.12237093 -68.06493647]\n",
      "116.12987294691305\n"
     ]
    }
   ],
   "source": [
    "P1 = np.array([0, 0, 0])\n",
    "P2 = np.array([5.9999, 0, 0])\n",
    "P3 = np.array([3, 3, 0])\n",
    "r1 = 3\n",
    "r2 = 3\n",
    "r3 = 3\n",
    "try:\n",
    "    p1, p2 = trilaterate(*anchors[[0,1,2]], *line_lengths.T[0][[0,1,2]].tolist())  # fails\n",
    "except ArithmeticError:\n",
    "    print('Exact intersection.')    \n",
    "print(p1, p2)\n",
    "print(np.linalg.norm(p1-p2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[151.81880145 175.40408403 169.05376243 163.02363717 191.86722696\n",
      " 159.33600953 153.15823437 148.03563606 156.63454458 179.34830214\n",
      " 171.2049141  159.72830495 159.83844501 164.09817765 145.21471858\n",
      " 170.20294085 104.2454243  120.41943    128.40740936 148.73510512\n",
      " 183.65311444 148.65247191 140.98883629 108.10921555 145.464387\n",
      " 145.11443343 182.70476023 107.02026887 136.37815391 146.26505609\n",
      " 168.5333952  152.45527197 150.55013362 129.479474   182.32203391\n",
      " 177.07191342 177.0346655  127.26574323 180.3108721  127.79415721\n",
      " 116.61412072 178.07672803 153.28258059 109.04136229  92.67014383\n",
      " 156.44351131 163.54958261 154.81694946 131.982222    92.87414795]\n",
      "[192.61964214 191.14483287 195.15554848 193.31520993 191.25899558\n",
      " 193.7241007  192.59653886 193.02665831 190.92629997 194.69431359\n",
      " 191.74133633 196.01108021 193.40352667 193.47058088 192.71638774\n",
      " 192.66047665 191.56753471 193.53211341 191.51801235 192.5264612\n",
      " 191.41706919 194.98492631 192.08480743 191.63521588 195.09018306\n",
      " 191.38716262 192.27183487 190.79895661 193.21079582 193.82007731\n",
      " 191.98492491 193.62115805 193.17899905 192.28001583 195.14374778\n",
      " 191.54890413 192.22359699 190.67204045 192.98529486 192.1790826\n",
      " 192.96295627 192.26182026 193.29257315 192.87263026 190.7198086\n",
      " 193.95694243 192.05321528 191.44916068 192.09498362 190.82606264]\n"
     ]
    }
   ],
   "source": [
    "# import itertools\n",
    "# def get_errors_between_trilats(anchors, line_lengths):\n",
    "#     intersections_by_point = []\n",
    "#     errors = []\n",
    "#     for point_index in range(line_lengths.shape[1]):\n",
    "#         intersections_by_anchor_combo = []\n",
    "#         inter_trilat_point_errors = []\n",
    "#         for anchor_index in itertools.combinations(range(len(anchors)), 3):\n",
    "#             # TODO: generalize to case when there's more than 1 validation anchor (ie len(anchors) > 4)\n",
    "#             anchor_subset = anchors[list(anchor_index)]\n",
    "#             anchor_val_index = np.setdiff1d(np.arange(line_lengths.shape[0]), anchor_index)\n",
    "#             anchor_val = anchors[anchor_val_index]\n",
    "            \n",
    "#             try:\n",
    "#                 try:\n",
    "#                     intersections_i = trilaterate(*anchor_subset, *line_lengths[anchor_index, point_index])\n",
    "#                 except ValueError:\n",
    "#                     intersections_by_anchor_combo.append([np.nan, np.nan, np.nan])\n",
    "#                     inter_trilat_point_errors.append(np.nan)\n",
    "#                     continue\n",
    "#             except ArithmeticError:\n",
    "#                 inter_trilat_point_errors.append(0.)\n",
    "#                 # print('Warning: No intersection possible, attempting with added noise.')\n",
    "#                 # intersections_noisy = []\n",
    "#                 # intersection_count = 0\n",
    "#                 # j = 0\n",
    "#                 # while intersection_count < 20 and j < 1000:\n",
    "#                 #     try:\n",
    "#                 #         # add noise, make noise grow slowly\n",
    "#                 #         line_lengths_noisy = line_lengths * (1 + (np.random.rand(*line_lengths.shape)-0.5) * (j+1)**(1/3)/100)\n",
    "#                 #         intersections_noisy.append(trilaterate(*anchor_subset, *line_lengths_noisy[anchor_index, i]))\n",
    "#                 #         intersection_count += 1\n",
    "#                 #         j += 1\n",
    "#                 #     except:\n",
    "#                 #         j += 1\n",
    "#                 # if intersection_count == 0:\n",
    "#                 #     raise ValueError('No intersections found.')\n",
    "#                 # elif intersection_count < 20:\n",
    "#                 #     print('Warning: low count of random intersections. Convergence might be bad.')\n",
    "#                 # intersections_i = np.array(intersections_noisy).mean(axis=0)\n",
    "#             # tie-brake between points using the 4th anchor\n",
    "#             dist0 = np.linalg.norm(anchor_val-intersections_i[0])\n",
    "#             dist1 = np.linalg.norm(anchor_val-intersections_i[1])\n",
    "#             radius_val = line_lengths[anchor_val_index, point_index]\n",
    "#             error_between_single_trilat_points = np.abs(radius_val-dist0) - np.abs(radius_val-dist1)\n",
    "#             if error_between_single_trilat_points < 0:\n",
    "#                 weighted_intersection = intersections_i[0] * 0.9 + intersections_i[1] * 0.1\n",
    "#             else:\n",
    "#                 weighted_intersection = intersections_i[1] * 0.9 + intersections_i[0] * 0.1\n",
    "#             inter_trilat_point_errors.append(abs(error_between_single_trilat_points.item()))\n",
    "#             intersections_by_anchor_combo.append(weighted_intersection)\n",
    "\n",
    "#         nan_filter = ~np.isnan(np.array(intersections_by_anchor_combo)).all(axis=1)\n",
    "#         intersections_by_anchor_combo = np.array(intersections_by_anchor_combo)[nan_filter]\n",
    "#         inter_trilat_point_errors = np.array(inter_trilat_point_errors)[nan_filter]\n",
    "#         point_estimate = np.average(intersections_by_anchor_combo, weights=inter_trilat_point_errors, axis=0)\n",
    "#         intersections_by_point.append(np.array(point_estimate))\n",
    "#         errors.append(inter_trilat_point_errors.sum())\n",
    "\n",
    "#     return np.array(errors)\n",
    "\n",
    "# trilat_errors_noisy = get_errors_between_trilats(noisy_anchors, noisy_line_lengths)\n",
    "# trilat_errors = get_errors_between_trilats(anchors, line_lengths)\n",
    "\n",
    "# # estimated_intersections = estimated_intersections_anchor.mean(axis=0)\n",
    "# # estimated_intersections\n",
    "# print(trilat_errors_noisy)\n",
    "# print(trilat_errors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/92/xt0q79l947bcltlw2c8gyr1h0000gn/T/ipykernel_1047/3014330465.py:38: RuntimeWarning: Mean of empty slice\n",
      "  inter_intersection_distance = np.nanmean(np.array(distances))\n"
     ]
    },
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/aldo.marini/code/winch/klipper/auto_calibration.ipynb Cell 19\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aldo.marini/code/winch/klipper/auto_calibration.ipynb#X23sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mfor\u001b[39;00m point_combo \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mcombinations(\u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(estimated_intersections_anchor)), \u001b[39m2\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aldo.marini/code/winch/klipper/auto_calibration.ipynb#X23sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     point_diff \u001b[39m=\u001b[39m estimated_intersections_anchor[point_combo[\u001b[39m0\u001b[39m]] \u001b[39m-\u001b[39m estimated_intersections_anchor[point_combo[\u001b[39m1\u001b[39m]]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/aldo.marini/code/winch/klipper/auto_calibration.ipynb#X23sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     distance \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49mnorm(point_diff, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aldo.marini/code/winch/klipper/auto_calibration.ipynb#X23sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     distances\u001b[39m.\u001b[39mappend(distance)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aldo.marini/code/winch/klipper/auto_calibration.ipynb#X23sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m inter_intersection_distance \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnanmean(np\u001b[39m.\u001b[39marray(distances))\n",
      "File \u001b[0;32m~/miniforge3/envs/klipper/lib/python3.11/site-packages/numpy/linalg/linalg.py:2583\u001b[0m, in \u001b[0;36mnorm\u001b[0;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[1;32m   2580\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mord\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mord\u001b[39m \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m   2581\u001b[0m     \u001b[39m# special case for speedup\u001b[39;00m\n\u001b[1;32m   2582\u001b[0m     s \u001b[39m=\u001b[39m (x\u001b[39m.\u001b[39mconj() \u001b[39m*\u001b[39m x)\u001b[39m.\u001b[39mreal\n\u001b[0;32m-> 2583\u001b[0m     \u001b[39mreturn\u001b[39;00m sqrt(add\u001b[39m.\u001b[39mreduce(s, axis\u001b[39m=\u001b[39maxis, keepdims\u001b[39m=\u001b[39mkeepdims))\n\u001b[1;32m   2584\u001b[0m \u001b[39m# None of the str-type keywords for ord ('fro', 'nuc')\u001b[39;00m\n\u001b[1;32m   2585\u001b[0m \u001b[39m# are valid for vectors\u001b[39;00m\n\u001b[1;32m   2586\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mord\u001b[39m, \u001b[39mstr\u001b[39m):\n",
      "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "# sample_sizes = [1, 10, 100, 1000]\n",
    "\n",
    "# anchors = np.array(\n",
    "#     [\n",
    "#         [0, 0, 0],\n",
    "#         [100, 0, 0],\n",
    "#         [50, 100, 0],\n",
    "#         [50, 50, 100]\n",
    "#         ]\n",
    "#     )\n",
    "\n",
    "# points = simulate_points(max(sample_sizes), radius=5, center=[50, 50, 50])\n",
    "# line_lengths = find_line_lengths(points, anchors)\n",
    "\n",
    "# # add noise to anchors and lengths\n",
    "# noisy_anchors = anchors + (np.random.rand(*anchors.shape)-0.5)*10/5 * 10\n",
    "# noisy_anchors = np.array(\n",
    "#     [\n",
    "#         [0, 0, 0],\n",
    "#         [100, 0, 0],\n",
    "#         [50, 100, 0],\n",
    "#         [51, 49, 105]\n",
    "#         ]\n",
    "#     )\n",
    "# # noisy_line_lengths = line_lengths #* (1 + (np.random.rand(*line_lengths.shape)-0.5) * 1/100)\n",
    "\n",
    "# scores = []\n",
    "# for num_points in sample_sizes:\n",
    "#     estimated_intersections_anchor = find_intersections(noisy_anchors, line_lengths[:, :num_points])\n",
    "#     estimated_intersections = np.nanmean(estimated_intersections_anchor, axis=0)  # average across anchors\n",
    "#     estimated_intersections_sigma = np.nanstd(estimated_intersections_anchor, axis=0)\n",
    "#     errors = np.linalg.norm(points[:num_points] - estimated_intersections, axis=1)\n",
    "#     distances = []\n",
    "#     for point_combo in itertools.combinations(range(len(estimated_intersections_anchor)), 2):\n",
    "#         point_diff = estimated_intersections_anchor[point_combo[0]] - estimated_intersections_anchor[point_combo[1]]\n",
    "#         distance = np.linalg.norm(point_diff, axis=1)\n",
    "#         distances.append(distance)\n",
    "#     inter_intersection_distance = np.nanmean(np.array(distances))\n",
    "#     scores.append((num_points, inter_intersection_distance, errors.mean(), estimated_intersections_sigma.mean()))\n",
    "# scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean(x, hat_line_lengths, measured_points, num_points_grid, num_points_torque):\n",
    "    anchors = x[:4*3].reshape(4, 3)\n",
    "    line_init = x[4*3:4*3+4]\n",
    "\n",
    "    line_lengths = find_line_lengths(measured_points[:num_points_grid], anchors[:, :num_points_grid])\n",
    "    sqerror = (line_lengths - (hat_line_lengths[:, :num_points_grid] + line_init[:, None]))**2\n",
    "    return sqerror.sum()  # sum across anchors and data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_anchor(x, line_init, hat_line_lengths, measured_points, num_points_grid, num_points_torque):\n",
    "    x = np.concatenate([x, line_init])\n",
    "    return euclidean(x, hat_line_lengths, measured_points, num_points_grid, num_points_torque)\n",
    "\n",
    "def euclidean_anchor_d(x, line_init, hat_line_lengths, measured_points, num_points_grid, num_points_torque):\n",
    "    x = np.concatenate([x[:-1], line_init[:-1], x[-1:]])\n",
    "    return euclidean(x, hat_line_lengths, measured_points, num_points_grid, num_points_torque)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = np.zeros_like(anchors)\n",
    "# a[0,0] = 0.\n",
    "# ll = find_line_lengths(measured_points, anchors+a)\n",
    "# x = np.concatenate([anchors.flatten(), np.array([0, 0, 0, 0])], axis=0)\n",
    "\n",
    "# euclidean(x, hat_line_lengths=ll, measured_points=measured_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inter_anchor_combo_distance(x, hat_line_lengths, num_points=20, measured_points=[]):\n",
    "    anchors = x[:4*3].reshape(4, 3)\n",
    "    line_init = x[4*3:4*3+4]\n",
    "\n",
    "    line_lengths = hat_line_lengths[:, :num_points] + line_init[:, None]\n",
    "    try:\n",
    "        estimated_intersections_anchor = find_intersections(anchors, line_lengths)\n",
    "    except ArithmeticError:\n",
    "        return 0.\n",
    "    distances = []\n",
    "    for point_combo in itertools.combinations(range(len(estimated_intersections_anchor)), 2):\n",
    "        # point_diff = estimated_intersections_anchor[point_combo[0]] - estimated_intersections_anchor[point_combo[1]]\n",
    "        # distance_between_trilat_points = np.linalg.norm(point_diff, axis=1)\n",
    "        distances.append(distance_between_trilat_points)\n",
    "    distances = np.array(distances)\n",
    "    mean_distance = np.nanmean(distances)\n",
    "    if np.isnan(mean_distance):\n",
    "        return 9999.\n",
    "    else:\n",
    "        return mean_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inter_anchor_and_euclidean(x, measured_line_lengths, measured_points, num_points_grid, num_points_torque):\n",
    "    # print(x)\n",
    "    inter = multilaterate_errors(x, measured_line_lengths[:, num_points_grid:], num_points_grid=None, num_points_torque=num_points_torque)\n",
    "    euc = euclidean(x, measured_line_lengths[:, :num_points_grid], measured_points[:num_points_grid], num_points_grid=num_points_grid, num_points_torque=None)\n",
    "    # print('inter', inter)\n",
    "    # print('euc', euc)\n",
    "\n",
    "    return euc + inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inter_anchor_and_euclidean_anchor(x, line_init, measured_line_lengths, measured_points, num_points_grid, num_points_torque):\n",
    "    x = np.concatenate([x, line_init])\n",
    "    return inter_anchor_and_euclidean(x, measured_line_lengths, measured_points, num_points_grid, num_points_torque)\n",
    "\n",
    "def inter_anchor_and_euclidean_line_init(x, anchor, measured_line_lengths, measured_points, num_points_grid, num_points_torque):\n",
    "    x = np.concatenate([anchor, x])\n",
    "    return inter_anchor_and_euclidean(x, measured_line_lengths, measured_points, num_points_grid, num_points_torque)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "from collections import defaultdict\n",
    "\n",
    "line_init = np.array([100, 200, 300, 100])\n",
    "# hat_line_lengths = line_lengths - line_init[:, None]\n",
    "\n",
    "measured_points = np.array([\n",
    "                            [50., 50., 10.], [70., 50., 10.], [50., 70., 10.], [30., 50., 10.], [50., 30., 10.],\n",
    "                            [70., 70., 10.], [30., 70., 10.], [30., 30., 10.], [70., 30., 10.],\n",
    "                            [50., 50., 50.], [70., 50., 50.], [50., 70., 50.], [30., 50., 15.], [50., 30., 15.],\n",
    "                            ])\n",
    "################################################################\n",
    "sim_measured_points = simulate_points(5000, radius=40, center=np.array([50, 50, 50]))\n",
    "grid_points = np.concatenate([measured_points, sim_measured_points], axis=0)\n",
    "################################################################\n",
    "measured_line_lengths = find_line_lengths(grid_points, anchors)\n",
    "grid_points[:measured_points.shape[0], :measured_points.shape[1]] += (np.random.rand(*measured_points.shape)-0.5)*2 * 3*4.5e-5 # encoder precision is 4.5e-5\n",
    "measured_line_lengths -= line_init[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(inter_anchor_and_euclidean(np.concatenate([anchors.flatten(), line_init.flatten()]), measured_line_lengths, measured_points, num_points_grid, num_points_torque),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000325\n",
      "         Iterations: 69\n",
      "         Function evaluations: 1036\n",
      "         Gradient evaluations: 74\n",
      "[[0.000 0.000 -0.001]\n",
      " [100.680 -0.681 -0.447]\n",
      " [50.000 100.000 -0.000]\n",
      " [50.000 50.000 99.999]]\n",
      "[100.000 201.000 300.000 99.999]\n",
      "SUCCESS 0.0008318202897691233\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "\n",
    "# grid search\n",
    "options = {\n",
    "        #    'Powell': {'gtol': 1e-10, 'disp': True, 'maxiter': 1e3},\n",
    "        #    'SLSQP': {'disp': True, 'maxiter': 1e5},\n",
    "        #    'Nelder-Mead': {'maxfev': 50000, 'return_all': True, 'maxiter': 1e3},\n",
    "           'BFGS': {'gtol': 1e-5, 'disp': True, 'maxiter': 1e5},\n",
    "        #    'CG': {'gtol': 1e-2, 'disp': True, 'maxiter': 1e5},\n",
    "           }\n",
    "\n",
    "num_points_grid = 5\n",
    "num_points_torque = 100\n",
    "from scipy.optimize import basinhopping, differential_evolution\n",
    "\n",
    "sols = defaultdict(list)\n",
    "for i in range(1):\n",
    "    # different anchor locations\n",
    "    x0 = np.concatenate([(anchors + (np.random.rand(*anchors.shape)-0.5)*2 * 10).flatten(),\n",
    "                        #  np.array([105, 185, 280, 90])])\n",
    "                         np.array([100., 201, 300, 150])])\n",
    "    # x0 = np.concatenate([(anchors).flatten(),\n",
    "    #                     np.array([100, 200, 100, 90])])\n",
    "    for method in options.keys():\n",
    "            # sols[(method, loss)].append(\n",
    "                # perhaps a two part iteration of cables + anchors would work better\n",
    "                # minimize(inputs[loss][0], args=(measured_line_lengths, grid_points, num_points_grid, num_points_torque),\n",
    "                #          method=method,\n",
    "                #          options=options[method],\n",
    "                #          tol=1e-5,\n",
    "                #          x0=x0)\n",
    "                # for i in range(10):\n",
    "                    # res = minimize(inter_anchor_and_euclidean_line_init, args=(x0[:4*3], measured_line_lengths, grid_points, num_points_grid, num_points_torque),\n",
    "                    #         method=method,\n",
    "                    #         options=options[method],\n",
    "                    #         tol=1e-5,\n",
    "                    #         x0=x0[4*3:4*3+4])\n",
    "                    # x0 = np.concatenate([x0[:4*3], res.x])\n",
    "                    # if inter_anchor_and_euclidean(x0, measured_line_lengths, grid_points, num_points_grid, num_points_torque) < 1e-4:\n",
    "                    #      break\n",
    "                    # res = minimize(euclidean_anchor, args=(x0[4*3:4*3+4], measured_line_lengths, grid_points, num_points_grid, num_points_torque),\n",
    "                    #         method=method,\n",
    "                    #         options=options[method],\n",
    "                    #         tol=1e-5,\n",
    "                    #         x0=x0[:4*3])\n",
    "                    # x0 = np.concatenate([res.x, x0[4*3:4*3+4]])\n",
    "                    res = minimize(euclidean_anchor_d, args=(x0[4*3:4*3+4], measured_line_lengths, grid_points, num_points_grid, num_points_torque),\n",
    "                            method=method,\n",
    "                            options=options[method],\n",
    "                            tol=1e-5,\n",
    "                            x0=np.concatenate([x0[:4*3], x0[-1:]])\n",
    "                    )\n",
    "                    x0 = np.concatenate([res.x[:-1], x0[4*3:4*3+4-1], res.x[-1:]])\n",
    "                    print(x0[:4*3].reshape(4,3))\n",
    "                    print(x0[4*3:])\n",
    "                    # 1: up to ~0.50 cum line error in ABC, ~0.2 in D with 5 grid points\n",
    "                    if (metric:=inter_anchor_and_euclidean(x0, measured_line_lengths, grid_points, num_points_grid, num_points_torque)) < 1:\n",
    "                        print('SUCCESS', metric)\n",
    "                    else:\n",
    "                        print('IMPRECISE', metric)\n",
    "                        print('INCREASING NUMBER OF SAMPLES')\n",
    "                        num_points_grid = 10\n",
    "                        # def stopper_callback(x, f, accepted):\n",
    "                        #      print(f, flush=True)\n",
    "                        #      return f < 1e-5\n",
    "                        # res = basinhopping(\n",
    "                        #             inter_anchor_and_euclidean,\n",
    "                        #             minimizer_kwargs={'method': method,\n",
    "                        #                               'args': (measured_line_lengths, grid_points, num_points_grid, num_points_torque),\n",
    "                        #                               'options': {**options[method],\n",
    "                        #                                           'maxiter': 2, 'gtol': 1e-2},\n",
    "                        #                               'tol': 1e-1},\n",
    "                        #             T=10,\n",
    "                        #             stepsize=6,\n",
    "                        #             callback=stopper_callback,\n",
    "                        #             x0=x0)\n",
    "                        NUM_ITER = 10\n",
    "                        i = 0\n",
    "                        x0_prev = x0.copy()\n",
    "                        while True:\n",
    "                            res = minimize(euclidean, args=(measured_line_lengths, grid_points, num_points_grid, num_points_torque),\n",
    "                                method=method,\n",
    "                                options={**options[method],\n",
    "                                        'maxiter': 1e4,\n",
    "                                        'gtol': 1e-4},\n",
    "                                tol=1e-5,\n",
    "                                x0=np.concatenate([(x0_prev[:4*3] + (np.random.rand(4*3)-0.5)*2 * 40).flatten(),\n",
    "                                                    x0_prev[4*3:4*3+4]])\n",
    "                            )\n",
    "                            x0 = res.x\n",
    "                            print(x0[:4*3].reshape(4,3))\n",
    "                            print(x0[4*3:])\n",
    "                            if i == NUM_ITER and (metric:=inter_anchor_and_euclidean(x0, measured_line_lengths, grid_points, num_points_grid, num_points_torque)):\n",
    "                                 print('FAILED', metric)\n",
    "                                 break\n",
    "                            if (metric:=inter_anchor_and_euclidean(x0, measured_line_lengths, grid_points, num_points_grid, num_points_torque)) < 1:\n",
    "                                print('SUCCESS', metric)\n",
    "                                break\n",
    "                            else:\n",
    "                                print('IMPRECISE, RETRYING', metric)\n",
    "                            i += 1\n",
    "                # differential_evolution(shorty, x0=x0, bounds=[[0, 100] for _ in range(12)] + [[-500, 500] for _ in range(4)])\n",
    "            # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000325\n",
      "         Iterations: 71\n",
      "         Function evaluations: 1064\n",
      "         Gradient evaluations: 76\n",
      "[[0.000 0.000 -0.001]\n",
      " [100.680 -0.681 -0.447]\n",
      " [50.000 100.000 -0.000]\n",
      " [50.000 50.000 99.999]]\n",
      "[100.000 201.000 300.000 99.999]\n",
      "SUCCESS 0.000831935572752305\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "\n",
    "# grid search\n",
    "options = {\n",
    "        #    'Powell': {'gtol': 1e-10, 'disp': True, 'maxiter': 1e3},\n",
    "        #    'SLSQP': {'disp': True, 'maxiter': 1e5},\n",
    "        #    'Nelder-Mead': {'maxfev': 50000, 'return_all': True, 'maxiter': 1e3},\n",
    "           'BFGS': {'gtol': 1e-5, 'disp': True, 'maxiter': 1e5},\n",
    "        #    'CG': {'gtol': 1e-2, 'disp': True, 'maxiter': 1e5},\n",
    "           }\n",
    "inputs = {\n",
    "        #   'euclidean': (euclidean,),\n",
    "        #   'inter': (inter_anchor_combo_distance, line_lengths - line_init[:, None]),\n",
    "          'both': (inter_anchor_and_euclidean,),\n",
    "         }\n",
    "\n",
    "num_points_grid = 5\n",
    "num_points_torque = 100\n",
    "from scipy.optimize import basinhopping, differential_evolution\n",
    "\n",
    "sols = defaultdict(list)\n",
    "for i in range(1):\n",
    "    # different anchor locations\n",
    "    x0 = np.concatenate([(anchors + (np.random.rand(*anchors.shape)-0.5)*2 * 10).flatten(),\n",
    "                        #  np.array([105, 185, 280, 90])])\n",
    "                         np.array([100., 201, 300, 150])])\n",
    "    # x0 = np.concatenate([(anchors).flatten(),\n",
    "    #                     np.array([100, 200, 100, 90])])\n",
    "    for method in options.keys():\n",
    "        for loss in inputs.keys():\n",
    "            # sols[(method, loss)].append(\n",
    "                # perhaps a two part iteration of cables + anchors would work better\n",
    "                # minimize(inputs[loss][0], args=(measured_line_lengths, grid_points, num_points_grid, num_points_torque),\n",
    "                #          method=method,\n",
    "                #          options=options[method],\n",
    "                #          tol=1e-5,\n",
    "                #          x0=x0)\n",
    "                # for i in range(10):\n",
    "                    # res = minimize(inter_anchor_and_euclidean_line_init, args=(x0[:4*3], measured_line_lengths, grid_points, num_points_grid, num_points_torque),\n",
    "                    #         method=method,\n",
    "                    #         options=options[method],\n",
    "                    #         tol=1e-5,\n",
    "                    #         x0=x0[4*3:4*3+4])\n",
    "                    # x0 = np.concatenate([x0[:4*3], res.x])\n",
    "                    # if inter_anchor_and_euclidean(x0, measured_line_lengths, grid_points, num_points_grid, num_points_torque) < 1e-4:\n",
    "                    #      break\n",
    "                    # res = minimize(euclidean_anchor, args=(x0[4*3:4*3+4], measured_line_lengths, grid_points, num_points_grid, num_points_torque),\n",
    "                    #         method=method,\n",
    "                    #         options=options[method],\n",
    "                    #         tol=1e-5,\n",
    "                    #         x0=x0[:4*3])\n",
    "                    # x0 = np.concatenate([res.x, x0[4*3:4*3+4]])\n",
    "                    res = minimize(euclidean_anchor_d, args=(x0[4*3:4*3+4], measured_line_lengths, grid_points, num_points_grid, num_points_torque),\n",
    "                            method=method,\n",
    "                            options=options[method],\n",
    "                            tol=1e-5,\n",
    "                            x0=np.concatenate([x0[:4*3], x0[-1:]])\n",
    "                    )\n",
    "                    x0 = np.concatenate([res.x[:-1], x0[4*3:4*3+4-1], res.x[-1:]])\n",
    "                    print(x0[:4*3].reshape(4,3))\n",
    "                    print(x0[4*3:])\n",
    "                    # 1: up to ~0.50 cum line error in ABC, ~0.2 in D with 5 grid points\n",
    "                    if (metric:=inter_anchor_and_euclidean(x0, measured_line_lengths, grid_points, num_points_grid, num_points_torque)) < 1:\n",
    "                        print('SUCCESS', metric)\n",
    "                    else:\n",
    "                        print('IMPRECISE', metric)\n",
    "                        print('INCREASING NUMBER OF SAMPLES')\n",
    "                        num_points_grid = 10\n",
    "                        # def stopper_callback(x, f, accepted):\n",
    "                        #      print(f, flush=True)\n",
    "                        #      return f < 1e-5\n",
    "                        # res = basinhopping(\n",
    "                        #             inter_anchor_and_euclidean,\n",
    "                        #             minimizer_kwargs={'method': method,\n",
    "                        #                               'args': (measured_line_lengths, grid_points, num_points_grid, num_points_torque),\n",
    "                        #                               'options': {**options[method],\n",
    "                        #                                           'maxiter': 2, 'gtol': 1e-2},\n",
    "                        #                               'tol': 1e-1},\n",
    "                        #             T=10,\n",
    "                        #             stepsize=6,\n",
    "                        #             callback=stopper_callback,\n",
    "                        #             x0=x0)\n",
    "                        NUM_ITER = 10\n",
    "                        i = 0\n",
    "                        x0_prev = x0.copy()\n",
    "                        while True:\n",
    "                            res = minimize(euclidean, args=(measured_line_lengths, grid_points, num_points_grid, num_points_torque),\n",
    "                                method=method,\n",
    "                                options={**options[method],\n",
    "                                        'maxiter': 1e4,\n",
    "                                        'gtol': 1e-4},\n",
    "                                tol=1e-5,\n",
    "                                x0=np.concatenate([(x0_prev[:4*3] + (np.random.rand(4*3)-0.5)*2 * 40).flatten(),\n",
    "                                                    x0_prev[4*3:4*3+4]])\n",
    "                            )\n",
    "                            x0 = res.x\n",
    "                            print(x0[:4*3].reshape(4,3))\n",
    "                            print(x0[4*3:])\n",
    "                            if i == NUM_ITER and (metric:=inter_anchor_and_euclidean(x0, measured_line_lengths, grid_points, num_points_grid, num_points_torque)):\n",
    "                                 print('FAILED', metric)\n",
    "                                 break\n",
    "                            if (metric:=inter_anchor_and_euclidean(x0, measured_line_lengths, grid_points, num_points_grid, num_points_torque)) < 1:\n",
    "                                print('SUCCESS', metric)\n",
    "                                break\n",
    "                            else:\n",
    "                                print('IMPRECISE, RETRYING', metric)\n",
    "                            i += 1\n",
    "                # differential_evolution(shorty, x0=x0, bounds=[[0, 100] for _ in range(12)] + [[-500, 500] for _ in range(4)])\n",
    "            # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001620846652679436"
      ]
     },
     "execution_count": 848,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sensitivity analysis\n",
    "\n",
    "# 1 in init = 5\n",
    "# 1 in anchors ABC = 2-5 xy, 0.1 y\n",
    "# 1 in anchor D = 0.1 xy, 5 y\n",
    "\n",
    "# 0.5 in init = 1.4\n",
    "# 0.5 in anchors ABC = 0.07-1 xy, 0.04 y\n",
    "# 0.5 in anchor D = 0.03 xy, 1 y\n",
    "\n",
    "# 0.1 in init = 0.05\n",
    "# 0.1 in anchors ABC = 0.003-0.05 xy, 0.002 y\n",
    "# 0.1 in anchor D = 0.001 xy, 0.05 y\n",
    "\n",
    "anchors_trial = \\\n",
    "np.array([[  0,   0,   .1],\n",
    "       [100,   0,   0],\n",
    "       [ 50, 100,   0],\n",
    "       [ 50,  50, 100]])\n",
    "\n",
    "line_init_trial = \\\n",
    "np.array([100, 200, 300, 100])\n",
    "\n",
    "x0 = np.concatenate([anchors_trial.flatten(), line_init_trial.flatten()])\n",
    "inter_anchor_and_euclidean(x0, measured_line_lengths, grid_points, num_points_grid, num_points_torque)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0],\n",
       "       [100,   0,   0],\n",
       "       [ 50, 100,   0],\n",
       "       [ 50,  50, 100]])"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective: Determine a good cut-off for inter_anchor_and_euclidean values to pass as valid solution. Evaluate inter_anchor_and_euclidean function by passing exact anchor values and play with line lengths and vice-versa. Also, eval joint effect of changing both values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt:  1\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.407294\n",
      "         Iterations: 587\n",
      "         Function evaluations: 11135\n",
      "         Gradient evaluations: 655\n",
      "Attempt:  1\n",
      "         Current function value: 18.220192\n",
      "         Iterations: 263\n",
      "         Function evaluations: 6030\n",
      "         Gradient evaluations: 354\n",
      "Euclidean loss:  18.22019247637934\n",
      "Attempt:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aldo.marini/miniforge3/envs/klipper/lib/python3.11/site-packages/scipy/optimize/_minimize.py:705: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
      "  res = _minimize_bfgs(fun, x0, args, jac, callback, **options)\n",
      "/Users/aldo.marini/miniforge3/envs/klipper/lib/python3.11/site-packages/scipy/optimize/_minimize.py:705: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
      "  res = _minimize_bfgs(fun, x0, args, jac, callback, **options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Current function value: 142.762326\n",
      "         Iterations: 513\n",
      "         Function evaluations: 12166\n",
      "         Gradient evaluations: 715\n",
      "Euclidean loss:  142.76232572014024\n",
      "Attempt:  3\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.644698\n",
      "         Iterations: 307\n",
      "         Function evaluations: 5746\n",
      "         Gradient evaluations: 338\n",
      "Euclidean loss:  1.644697906749259\n",
      "Attempt:  4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.407799\n",
      "         Iterations: 321\n",
      "         Function evaluations: 6103\n",
      "         Gradient evaluations: 359\n",
      "Attempt:  1\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.799339\n",
      "         Iterations: 316\n",
      "         Function evaluations: 5984\n",
      "         Gradient evaluations: 352\n",
      "Euclidean loss:  1.7993389074030426\n",
      "Attempt:  2\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.602852\n",
      "         Iterations: 358\n",
      "         Function evaluations: 6868\n",
      "         Gradient evaluations: 404\n",
      "Attempt:  1\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.612142\n",
      "         Iterations: 116\n",
      "         Function evaluations: 2108\n",
      "         Gradient evaluations: 124\n",
      "Attempt:  1\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.562228\n",
      "         Iterations: 431\n",
      "         Function evaluations: 8228\n",
      "         Gradient evaluations: 484\n",
      "Euclidean loss:  1.5622279005441202\n",
      "Attempt:  2\n",
      "         Current function value: 19.804898\n",
      "         Iterations: 271\n",
      "         Function evaluations: 6305\n",
      "         Gradient evaluations: 370\n",
      "Euclidean loss:  19.804897971477995\n",
      "Attempt:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aldo.marini/miniforge3/envs/klipper/lib/python3.11/site-packages/scipy/optimize/_minimize.py:705: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
      "  res = _minimize_bfgs(fun, x0, args, jac, callback, **options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 21.985503\n",
      "         Iterations: 342\n",
      "         Function evaluations: 6681\n",
      "         Gradient evaluations: 393\n",
      "Euclidean loss:  21.98550349021506\n",
      "Attempt:  4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.393879\n",
      "         Iterations: 140\n",
      "         Function evaluations: 2584\n",
      "         Gradient evaluations: 152\n",
      "Attempt:  1\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.589910\n",
      "         Iterations: 341\n",
      "         Function evaluations: 6460\n",
      "         Gradient evaluations: 380\n",
      "Attempt:  1\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.573213\n",
      "         Iterations: 204\n",
      "         Function evaluations: 3774\n",
      "         Gradient evaluations: 222\n",
      "Attempt:  1\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.606261\n",
      "         Iterations: 163\n",
      "         Function evaluations: 3060\n",
      "         Gradient evaluations: 180\n",
      "Attempt:  1\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 22.949938\n",
      "         Iterations: 539\n",
      "         Function evaluations: 12088\n",
      "         Gradient evaluations: 711\n",
      "Euclidean loss:  22.949937531227775\n",
      "Attempt:  2\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.480005\n",
      "         Iterations: 241\n",
      "         Function evaluations: 4471\n",
      "         Gradient evaluations: 263\n",
      "Euclidean loss:  1.4800045664398138\n",
      "Attempt:  3\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 22.604110\n",
      "         Iterations: 409\n",
      "         Function evaluations: 7922\n",
      "         Gradient evaluations: 466\n",
      "Euclidean loss:  22.604110274466493\n",
      "Attempt:  4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.646990\n",
      "         Iterations: 186\n",
      "         Function evaluations: 3519\n",
      "         Gradient evaluations: 207\n",
      "Attempt:  1\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.487950\n",
      "         Iterations: 449\n",
      "         Function evaluations: 8959\n",
      "         Gradient evaluations: 527\n",
      "Attempt:  1\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.406169\n",
      "         Iterations: 334\n",
      "         Function evaluations: 6273\n",
      "         Gradient evaluations: 369\n",
      "Attempt:  1\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.480443\n",
      "         Iterations: 350\n",
      "         Function evaluations: 6681\n",
      "         Gradient evaluations: 393\n",
      "Attempt:  1\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.391791\n",
      "         Iterations: 348\n",
      "         Function evaluations: 6528\n",
      "         Gradient evaluations: 384\n",
      "Euclidean loss:  1.3917913245530293\n",
      "Attempt:  2\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.619844\n",
      "         Iterations: 390\n",
      "         Function evaluations: 7463\n",
      "         Gradient evaluations: 439\n",
      "Attempt:  1\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 2.135894\n",
      "         Iterations: 523\n",
      "         Function evaluations: 10149\n",
      "         Gradient evaluations: 597\n",
      "Euclidean loss:  2.135894008182086\n",
      "Attempt:  2\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.597895\n",
      "         Iterations: 219\n",
      "         Function evaluations: 4148\n",
      "         Gradient evaluations: 244\n",
      "Attempt:  1\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 9.986560\n",
      "         Iterations: 497\n",
      "         Function evaluations: 9758\n",
      "         Gradient evaluations: 574\n",
      "Euclidean loss:  9.986559556646515\n",
      "Attempt:  2\n",
      "         Current function value: 29.343925\n",
      "         Iterations: 569\n",
      "         Function evaluations: 11997\n",
      "         Gradient evaluations: 705\n",
      "Euclidean loss:  29.343924552411785\n",
      "Attempt:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aldo.marini/miniforge3/envs/klipper/lib/python3.11/site-packages/scipy/optimize/_minimize.py:705: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
      "  res = _minimize_bfgs(fun, x0, args, jac, callback, **options)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/aldo.marini/code/winch/klipper/auto_calibration.ipynb Cell 25\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aldo.marini/code/winch/klipper/auto_calibration.ipynb#X35sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39mfor\u001b[39;00m method \u001b[39min\u001b[39;00m options\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aldo.marini/code/winch/klipper/auto_calibration.ipynb#X35sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     \u001b[39mfor\u001b[39;00m loss \u001b[39min\u001b[39;00m inputs\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/aldo.marini/code/winch/klipper/auto_calibration.ipynb#X35sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m         sol \u001b[39m=\u001b[39m minimize(inputs[loss][\u001b[39m0\u001b[39;49m], args\u001b[39m=\u001b[39;49m(inputs[loss][\u001b[39m1\u001b[39;49m], num_points, gp),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aldo.marini/code/winch/klipper/auto_calibration.ipynb#X35sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m                         method\u001b[39m=\u001b[39;49mmethod,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aldo.marini/code/winch/klipper/auto_calibration.ipynb#X35sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m                         options\u001b[39m=\u001b[39;49moptions[method],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aldo.marini/code/winch/klipper/auto_calibration.ipynb#X35sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m                         tol\u001b[39m=\u001b[39;49m\u001b[39m1e-3\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aldo.marini/code/winch/klipper/auto_calibration.ipynb#X35sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m                         x0\u001b[39m=\u001b[39;49mx0)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aldo.marini/code/winch/klipper/auto_calibration.ipynb#X35sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m \u001b[39mif\u001b[39;00m (euc\u001b[39m:=\u001b[39meuclidean(sol\u001b[39m.\u001b[39mx, hat_line_lengths\u001b[39m=\u001b[39minputs[loss][\u001b[39m1\u001b[39m][:, :measured_line_lengths\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]], measured_points\u001b[39m=\u001b[39mgp, num_points\u001b[39m=\u001b[39mnum_points)) \u001b[39m>\u001b[39m \u001b[39m0.7\u001b[39m \\\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aldo.marini/code/winch/klipper/auto_calibration.ipynb#X35sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m         \u001b[39mand\u001b[39;00m num_try \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m \u001b[39m<\u001b[39m max_retries:  \u001b[39m# 1e-3 for theoretical\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aldo.marini/code/winch/klipper/auto_calibration.ipynb#X35sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mEuclidean loss: \u001b[39m\u001b[39m'\u001b[39m, euc)\n",
      "File \u001b[0;32m~/miniforge3/envs/klipper/lib/python3.11/site-packages/scipy/optimize/_minimize.py:705\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    703\u001b[0m     res \u001b[39m=\u001b[39m _minimize_cg(fun, x0, args, jac, callback, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n\u001b[1;32m    704\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mbfgs\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 705\u001b[0m     res \u001b[39m=\u001b[39m _minimize_bfgs(fun, x0, args, jac, callback, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moptions)\n\u001b[1;32m    706\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnewton-cg\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    707\u001b[0m     res \u001b[39m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[1;32m    708\u001b[0m                              \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n",
      "File \u001b[0;32m~/miniforge3/envs/klipper/lib/python3.11/site-packages/scipy/optimize/_optimize.py:1445\u001b[0m, in \u001b[0;36m_minimize_bfgs\u001b[0;34m(fun, x0, args, jac, callback, gtol, norm, eps, maxiter, disp, return_all, finite_diff_rel_step, xrtol, **unknown_options)\u001b[0m\n\u001b[1;32m   1442\u001b[0m pk \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39mdot(Hk, gfk)\n\u001b[1;32m   1443\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1444\u001b[0m     alpha_k, fc, gc, old_fval, old_old_fval, gfkp1 \u001b[39m=\u001b[39m \\\n\u001b[0;32m-> 1445\u001b[0m              _line_search_wolfe12(f, myfprime, xk, pk, gfk,\n\u001b[1;32m   1446\u001b[0m                                   old_fval, old_old_fval, amin\u001b[39m=\u001b[39;49m\u001b[39m1e-100\u001b[39;49m, amax\u001b[39m=\u001b[39;49m\u001b[39m1e100\u001b[39;49m)\n\u001b[1;32m   1447\u001b[0m \u001b[39mexcept\u001b[39;00m _LineSearchError:\n\u001b[1;32m   1448\u001b[0m     \u001b[39m# Line search failed to find a better solution.\u001b[39;00m\n\u001b[1;32m   1449\u001b[0m     warnflag \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/klipper/lib/python3.11/site-packages/scipy/optimize/_optimize.py:1215\u001b[0m, in \u001b[0;36m_line_search_wolfe12\u001b[0;34m(f, fprime, xk, pk, gfk, old_fval, old_old_fval, **kwargs)\u001b[0m\n\u001b[1;32m   1201\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1202\u001b[0m \u001b[39mSame as line_search_wolfe1, but fall back to line_search_wolfe2 if\u001b[39;00m\n\u001b[1;32m   1203\u001b[0m \u001b[39msuitable step length is not found, and raise an exception if a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1210\u001b[0m \n\u001b[1;32m   1211\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m extra_condition \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39mextra_condition\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m-> 1215\u001b[0m ret \u001b[39m=\u001b[39m line_search_wolfe1(f, fprime, xk, pk, gfk,\n\u001b[1;32m   1216\u001b[0m                          old_fval, old_old_fval,\n\u001b[1;32m   1217\u001b[0m                          \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1219\u001b[0m \u001b[39mif\u001b[39;00m ret[\u001b[39m0\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m extra_condition \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1220\u001b[0m     xp1 \u001b[39m=\u001b[39m xk \u001b[39m+\u001b[39m ret[\u001b[39m0\u001b[39m] \u001b[39m*\u001b[39m pk\n",
      "File \u001b[0;32m~/miniforge3/envs/klipper/lib/python3.11/site-packages/scipy/optimize/_linesearch.py:84\u001b[0m, in \u001b[0;36mline_search_wolfe1\u001b[0;34m(f, fprime, xk, pk, gfk, old_fval, old_old_fval, args, c1, c2, amax, amin, xtol)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mdot(gval[\u001b[39m0\u001b[39m], pk)\n\u001b[1;32m     82\u001b[0m derphi0 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(gfk, pk)\n\u001b[0;32m---> 84\u001b[0m stp, fval, old_fval \u001b[39m=\u001b[39m scalar_search_wolfe1(\n\u001b[1;32m     85\u001b[0m         phi, derphi, old_fval, old_old_fval, derphi0,\n\u001b[1;32m     86\u001b[0m         c1\u001b[39m=\u001b[39;49mc1, c2\u001b[39m=\u001b[39;49mc2, amax\u001b[39m=\u001b[39;49mamax, amin\u001b[39m=\u001b[39;49mamin, xtol\u001b[39m=\u001b[39;49mxtol)\n\u001b[1;32m     88\u001b[0m \u001b[39mreturn\u001b[39;00m stp, fc[\u001b[39m0\u001b[39m], gc[\u001b[39m0\u001b[39m], fval, old_fval, gval[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniforge3/envs/klipper/lib/python3.11/site-packages/scipy/optimize/_linesearch.py:161\u001b[0m, in \u001b[0;36mscalar_search_wolfe1\u001b[0;34m(phi, derphi, phi0, old_phi0, derphi0, c1, c2, amax, amin, xtol)\u001b[0m\n\u001b[1;32m    159\u001b[0m     alpha1 \u001b[39m=\u001b[39m stp\n\u001b[1;32m    160\u001b[0m     phi1 \u001b[39m=\u001b[39m phi(stp)\n\u001b[0;32m--> 161\u001b[0m     derphi1 \u001b[39m=\u001b[39m derphi(stp)\n\u001b[1;32m    162\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    163\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/klipper/lib/python3.11/site-packages/scipy/optimize/_linesearch.py:78\u001b[0m, in \u001b[0;36mline_search_wolfe1.<locals>.derphi\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mderphi\u001b[39m(s):\n\u001b[0;32m---> 78\u001b[0m     gval[\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m fprime(xk \u001b[39m+\u001b[39;49m s\u001b[39m*\u001b[39;49mpk, \u001b[39m*\u001b[39;49margs)\n\u001b[1;32m     79\u001b[0m     gc[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     80\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mdot(gval[\u001b[39m0\u001b[39m], pk)\n",
      "File \u001b[0;32m~/miniforge3/envs/klipper/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:273\u001b[0m, in \u001b[0;36mScalarFunction.grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39marray_equal(x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx):\n\u001b[1;32m    272\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_x_impl(x)\n\u001b[0;32m--> 273\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_grad()\n\u001b[1;32m    274\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mg\n",
      "File \u001b[0;32m~/miniforge3/envs/klipper/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:256\u001b[0m, in \u001b[0;36mScalarFunction._update_grad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update_grad\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    255\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mg_updated:\n\u001b[0;32m--> 256\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_grad_impl()\n\u001b[1;32m    257\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mg_updated \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/klipper/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:173\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_grad\u001b[0;34m()\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_fun()\n\u001b[1;32m    172\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mngev \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 173\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mg \u001b[39m=\u001b[39m approx_derivative(fun_wrapped, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx, f0\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf,\n\u001b[1;32m    174\u001b[0m                            \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfinite_diff_options)\n",
      "File \u001b[0;32m~/miniforge3/envs/klipper/lib/python3.11/site-packages/scipy/optimize/_numdiff.py:505\u001b[0m, in \u001b[0;36mapprox_derivative\u001b[0;34m(fun, x0, method, rel_step, abs_step, f0, bounds, sparsity, as_linear_operator, args, kwargs)\u001b[0m\n\u001b[1;32m    502\u001b[0m     use_one_sided \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    504\u001b[0m \u001b[39mif\u001b[39;00m sparsity \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 505\u001b[0m     \u001b[39mreturn\u001b[39;00m _dense_difference(fun_wrapped, x0, f0, h,\n\u001b[1;32m    506\u001b[0m                              use_one_sided, method)\n\u001b[1;32m    507\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    508\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m issparse(sparsity) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(sparsity) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n",
      "File \u001b[0;32m~/miniforge3/envs/klipper/lib/python3.11/site-packages/scipy/optimize/_numdiff.py:576\u001b[0m, in \u001b[0;36m_dense_difference\u001b[0;34m(fun, x0, f0, h, use_one_sided, method)\u001b[0m\n\u001b[1;32m    574\u001b[0m     x \u001b[39m=\u001b[39m x0 \u001b[39m+\u001b[39m h_vecs[i]\n\u001b[1;32m    575\u001b[0m     dx \u001b[39m=\u001b[39m x[i] \u001b[39m-\u001b[39m x0[i]  \u001b[39m# Recompute dx as exactly representable number.\u001b[39;00m\n\u001b[0;32m--> 576\u001b[0m     df \u001b[39m=\u001b[39m fun(x) \u001b[39m-\u001b[39m f0\n\u001b[1;32m    577\u001b[0m \u001b[39melif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m3-point\u001b[39m\u001b[39m'\u001b[39m \u001b[39mand\u001b[39;00m use_one_sided[i]:\n\u001b[1;32m    578\u001b[0m     x1 \u001b[39m=\u001b[39m x0 \u001b[39m+\u001b[39m h_vecs[i]\n",
      "File \u001b[0;32m~/miniforge3/envs/klipper/lib/python3.11/site-packages/scipy/optimize/_numdiff.py:456\u001b[0m, in \u001b[0;36mapprox_derivative.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfun_wrapped\u001b[39m(x):\n\u001b[0;32m--> 456\u001b[0m     f \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39matleast_1d(fun(x, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n\u001b[1;32m    457\u001b[0m     \u001b[39mif\u001b[39;00m f\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    458\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`fun` return value has \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    459\u001b[0m                            \u001b[39m\"\u001b[39m\u001b[39mmore than 1 dimension.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/klipper/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnfev \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    134\u001b[0m \u001b[39m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[39m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[39m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m fx \u001b[39m=\u001b[39m fun(np\u001b[39m.\u001b[39;49mcopy(x), \u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    138\u001b[0m \u001b[39m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39misscalar(fx):\n",
      "\u001b[1;32m/Users/aldo.marini/code/winch/klipper/auto_calibration.ipynb Cell 25\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/aldo.marini/code/winch/klipper/auto_calibration.ipynb#X35sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m anchors \u001b[39m=\u001b[39m x[:\u001b[39m4\u001b[39m\u001b[39m*\u001b[39m\u001b[39m3\u001b[39m]\u001b[39m.\u001b[39mreshape(\u001b[39m4\u001b[39m, \u001b[39m3\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/aldo.marini/code/winch/klipper/auto_calibration.ipynb#X35sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m line_init \u001b[39m=\u001b[39m x[\u001b[39m4\u001b[39m\u001b[39m*\u001b[39m\u001b[39m3\u001b[39m:\u001b[39m4\u001b[39m\u001b[39m*\u001b[39m\u001b[39m3\u001b[39m\u001b[39m+\u001b[39m\u001b[39m4\u001b[39m]\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/aldo.marini/code/winch/klipper/auto_calibration.ipynb#X35sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m line_lengths \u001b[39m=\u001b[39m find_line_lengths(measured_points, anchors)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/aldo.marini/code/winch/klipper/auto_calibration.ipynb#X35sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m sqerror \u001b[39m=\u001b[39m (line_lengths \u001b[39m-\u001b[39m (hat_line_lengths \u001b[39m+\u001b[39m line_init[:, \u001b[39mNone\u001b[39;00m]))\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/aldo.marini/code/winch/klipper/auto_calibration.ipynb#X35sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mreturn\u001b[39;00m sqerror\u001b[39m.\u001b[39msum()\n",
      "\u001b[1;32m/Users/aldo.marini/code/winch/klipper/auto_calibration.ipynb Cell 25\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/aldo.marini/code/winch/klipper/auto_calibration.ipynb#X35sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m line_lengths \u001b[39m=\u001b[39m []\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/aldo.marini/code/winch/klipper/auto_calibration.ipynb#X35sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m anchor \u001b[39min\u001b[39;00m anchors:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/aldo.marini/code/winch/klipper/auto_calibration.ipynb#X35sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     line_lengths\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49mnorm(points \u001b[39m-\u001b[39;49m anchor, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/aldo.marini/code/winch/klipper/auto_calibration.ipynb#X35sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m line_lengths \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(line_lengths)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/aldo.marini/code/winch/klipper/auto_calibration.ipynb#X35sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mreturn\u001b[39;00m line_lengths\n",
      "File \u001b[0;32m~/miniforge3/envs/klipper/lib/python3.11/site-packages/numpy/linalg/linalg.py:2379\u001b[0m, in \u001b[0;36m_norm_dispatcher\u001b[0;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[1;32m   2375\u001b[0m     result \u001b[39m=\u001b[39m op(svd(y, compute_uv\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m), axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m   2376\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[0;32m-> 2379\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_norm_dispatcher\u001b[39m(x, \u001b[39mord\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   2380\u001b[0m     \u001b[39mreturn\u001b[39;00m (x,)\n\u001b[1;32m   2383\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_norm_dispatcher)\n\u001b[1;32m   2384\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnorm\u001b[39m(x, \u001b[39mord\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_points_grid = 14\n",
    "max_retries = 10\n",
    "\n",
    "\n",
    "options = {\n",
    "        #    'Powell': {'gtol': 1e-10, 'disp': True, 'maxiter': 1e3},\n",
    "        #    'SLSQP': {'gtol': 1e-10, 'disp': True, 'maxiter': 1e3},\n",
    "        #    'Nelder-Mead': {'maxfev': 50000, 'return_all': True, 'maxiter': 1e4},\n",
    "           'BFGS': {'gtol': 1e-3, 'disp': True, 'maxiter': 1e5},\n",
    "        #    'CG': {'gtol': 1e-3, 'disp': True, 'maxiter': 1e4},\n",
    "           }\n",
    "inputs = {\n",
    "          'euclidean': [euclidean, measured_line_lengths[:, :num_points_grid]],\n",
    "        #   'inter': [inter_anchor_combo_distance, line_lengths - line_init[:, None]] ,\n",
    "        #   'both': [inter_anchor_and_euclidean, np.concatenate([measured_line_lengths, hat_line_lengths], axis=1)],\n",
    "         }\n",
    "\n",
    "gp = grid_points[:num_points_grid]\n",
    "\n",
    "num_failures = 0\n",
    "retry_failure = 0\n",
    "\n",
    "loss = 'euclidean'\n",
    "\n",
    "sols = defaultdict(list)\n",
    "og_input = find_line_lengths(grid_points, anchors)\n",
    "for point_index in range(35):\n",
    "    grid_shaky_points = grid_points + (np.random.rand(*grid_points.shape)-0.5)*2 * 0.2\n",
    "    shaky_lengths = find_line_lengths(grid_shaky_points, anchors)[:, :num_points_grid] - line_init[:, None]\n",
    "    inputs[loss][1] = shaky_lengths\n",
    "    measured_anchors = (anchors + (np.random.rand(*anchors.shape)-0.5)*2 * 20).flatten()\n",
    "    for num_try in range(max_retries):\n",
    "        print('Attempt: ', num_try+1)\n",
    "        # different anchor locations\n",
    "        x0 = np.concatenate([measured_anchors,\n",
    "                            #  (line_init + (np.random.rand(*line_init.shape)-0.5)*2 * 200).flatten(),\n",
    "                            1000 * np.random.rand(*line_init.shape),\n",
    "                            ])\n",
    "        for method in options.keys():\n",
    "            for loss in inputs.keys():\n",
    "                sol = minimize(inputs[loss][0], args=(inputs[loss][1], num_points, gp),\n",
    "                                method=method,\n",
    "                                options=options[method],\n",
    "                                tol=1e-3,\n",
    "                                x0=x0)\n",
    "        if (euc:=euclidean(sol.x, hat_line_lengths=inputs[loss][1][:, :measured_line_lengths.shape[1]], measured_points=gp, num_points=num_points)) > 0.7 \\\n",
    "                and num_try + 1 < max_retries:  # 1e-3 for theoretical\n",
    "            print('Euclidean loss: ', euc)\n",
    "            num_failures += 1\n",
    "            continue\n",
    "        else:\n",
    "            if num_try + 1 == max_retries:\n",
    "                retry_failure += 1\n",
    "            sols[(method, loss)].append(dict(\n",
    "                sol=sol,\n",
    "                anchor_measure_error=np.abs(sol.x[:np.multiply(*anchors.shape)] - anchors.flatten()).mean(),\n",
    "                line_measure_error=np.abs(sol.x[np.multiply(*anchors.shape):] - line_init).mean(),\n",
    "                anchor_loss = ((sol.x[:np.multiply(*anchors.shape)].reshape(*anchors.shape) - anchors)**2).mean()**(1/2),\n",
    "                line_loss = ((sol.x[np.multiply(*anchors.shape):] - line_init)**2).mean()**(1/2),\n",
    "                status = sol.status\n",
    "            ))\n",
    "            break\n",
    "\n",
    "num_failures, retry_failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('max anchor_loss', 3482.4294390250707, '\\nmax line_loss', 6024.365184332065)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'max anchor_loss', max([s['anchor_loss'] for s in sols[('BFGS', 'euclidean')]]), '\\nmax line_loss', max([s['line_loss'] for s in sols[('BFGS', 'euclidean')]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_points   failures    retry_failure\n",
    "# 6 h 10-50    127         3\n",
    "# 5 l 1 h 50   141         5\n",
    "# 3 l 3 h      125         6\n",
    "# 6 l 1 h 50   123         4\n",
    "# 5 l 2 h 50 x 103         3\n",
    "# 5 l 2 h 50   48, 55      0, 0\n",
    "# 4 l 3 h 50 x 90          0\n",
    "# 5 l 3 h 50   64          0\n",
    "# 4 l 3 h 50   65, 48, 64  1, 1, 2\n",
    "# 9            206         18\n",
    "# 10 rand      187\n",
    "# 10           213, 252    16, 24\n",
    "# 9 l 1 h 50   55          0\n",
    "# 10 h 10-11   73          1\n",
    "# 10 h 10-15   11, 10      0\n",
    "# 10 h 10-20   33          0\n",
    "# 10 h 10-30   18          0\n",
    "# 14 5 rand    52, 51      1\n",
    "# 14           38, 43      0, 0\n",
    "# 14 high 30   11          0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/92/xt0q79l947bcltlw2c8gyr1h0000gn/T/ipykernel_62730/2714022985.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msols\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'BFGS'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'euclidean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mline_loss\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manchor_loss\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# stats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "stats = pd.DataFrame(sols[('BFGS', 'euclidean')])\n",
    "len(stats[(stats.line_loss < 1) & (stats.anchor_loss < 1)])\n",
    "# stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>CG</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>euclidean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anchor_loss</th>\n",
       "      <td>0.004993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anchor_max</th>\n",
       "      <td>0.004993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line_loss</th>\n",
       "      <td>0.008596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line_max</th>\n",
       "      <td>0.008596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>status</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   CG\n",
       "            euclidean\n",
       "anchor_loss  0.004993\n",
       "anchor_max   0.004993\n",
       "line_loss    0.008596\n",
       "line_max     0.008596\n",
       "status              0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "res = {}\n",
    "for name, values in sols.items():\n",
    "    sol_list = values[0]    \n",
    "    anchor_loss = np.mean([((sol.x[:4*3].reshape(4,3) - anchors)**2).mean()**(1/2) for sol in sol_list])\n",
    "    line_loss = np.mean([((sol.x[4*3:] - line_init)**2).mean()**(1/2) for sol in sol_list])\n",
    "    anchor_max = np.max([((sol.x[:4*3].reshape(4,3) - anchors)**2).mean()**(1/2) for sol in sol_list])\n",
    "    line_max = np.max([((sol.x[4*3:] - line_init)**2).mean()**(1/2) for sol in sol_list])\n",
    "    status = ''.join([str(sol.status) for sol in sol_list])\n",
    "    res[name] = {'anchor_loss': anchor_loss, 'line_loss': line_loss, 'anchor_max': anchor_max, 'line_max': line_max, 'status': status}\n",
    "pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">BFGS</th>\n",
       "      <th colspan=\"3\" halign=\"left\">CG</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>euclidean</th>\n",
       "      <th>inter</th>\n",
       "      <th>both</th>\n",
       "      <th>euclidean</th>\n",
       "      <th>inter</th>\n",
       "      <th>both</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anchor_loss</th>\n",
       "      <td>11.428393</td>\n",
       "      <td>12.59487</td>\n",
       "      <td>11.429803</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>11.780084</td>\n",
       "      <td>0.001342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line_loss</th>\n",
       "      <td>20.607131</td>\n",
       "      <td>12.359723</td>\n",
       "      <td>20.609428</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>13.029805</td>\n",
       "      <td>0.00228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anchor_max</th>\n",
       "      <td>39.953429</td>\n",
       "      <td>13.83018</td>\n",
       "      <td>39.954191</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>13.985962</td>\n",
       "      <td>0.003117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line_max</th>\n",
       "      <td>71.689287</td>\n",
       "      <td>13.693064</td>\n",
       "      <td>71.690534</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>13.693064</td>\n",
       "      <td>0.005301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>status</th>\n",
       "      <td>2222222222</td>\n",
       "      <td>0200000200</td>\n",
       "      <td>2222222222</td>\n",
       "      <td>2222222222</td>\n",
       "      <td>0002200000</td>\n",
       "      <td>2222222222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   BFGS                                  CG              \\\n",
       "              euclidean       inter        both   euclidean       inter   \n",
       "anchor_loss   11.428393    12.59487   11.429803    0.000151   11.780084   \n",
       "line_loss     20.607131   12.359723   20.609428    0.000257   13.029805   \n",
       "anchor_max    39.953429    13.83018   39.954191    0.000316   13.985962   \n",
       "line_max      71.689287   13.693064   71.690534    0.000538   13.693064   \n",
       "status       2222222222  0200000200  2222222222  2222222222  0002200000   \n",
       "\n",
       "                         \n",
       "                   both  \n",
       "anchor_loss    0.001342  \n",
       "line_loss       0.00228  \n",
       "anchor_max     0.003117  \n",
       "line_max       0.005301  \n",
       "status       2222222222  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# quadratic euc\n",
    "# MASSIVE gains from using two different z-levels for sampling euclidean\n",
    "# 5 extra 10cm above euc non-random data points\n",
    "import pandas as pd\n",
    "res = {}\n",
    "for name, sol_list in sols.items():\n",
    "    anchor_loss = np.mean([((sol.x[:4*3].reshape(4,3) - anchors)**2).mean()**(1/2) for sol in sol_list])\n",
    "    line_loss = np.mean([((sol.x[4*3:] - line_init)**2).mean()**(1/2) for sol in sol_list])\n",
    "    anchor_max = np.max([((sol.x[:4*3].reshape(4,3) - anchors)**2).mean()**(1/2) for sol in sol_list])\n",
    "    line_max = np.max([((sol.x[4*3:] - line_init)**2).mean()**(1/2) for sol in sol_list])\n",
    "    status = ''.join([str(sol.status) for sol in sol_list])\n",
    "    res[name] = {'anchor_loss': anchor_loss, 'line_loss': line_loss, 'anchor_max': anchor_max, 'line_max': line_max, 'status': status}\n",
    "pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">BFGS</th>\n",
       "      <th colspan=\"3\" halign=\"left\">CG</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>euclidean</th>\n",
       "      <th>inter</th>\n",
       "      <th>both</th>\n",
       "      <th>euclidean</th>\n",
       "      <th>inter</th>\n",
       "      <th>both</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anchor_loss</th>\n",
       "      <td>0.000109</td>\n",
       "      <td>11.340306</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>5.822015</td>\n",
       "      <td>12.106086</td>\n",
       "      <td>6.003193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line_loss</th>\n",
       "      <td>0.000185</td>\n",
       "      <td>12.071454</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>9.605169</td>\n",
       "      <td>12.787283</td>\n",
       "      <td>9.647818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anchor_max</th>\n",
       "      <td>0.000496</td>\n",
       "      <td>13.864297</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>7.745047</td>\n",
       "      <td>17.241418</td>\n",
       "      <td>7.729335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line_max</th>\n",
       "      <td>0.000839</td>\n",
       "      <td>13.76909</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>13.076488</td>\n",
       "      <td>18.455082</td>\n",
       "      <td>13.143444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>status</th>\n",
       "      <td>2222222222</td>\n",
       "      <td>2200022020</td>\n",
       "      <td>2222222222</td>\n",
       "      <td>2222222222</td>\n",
       "      <td>2200022020</td>\n",
       "      <td>2222222222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   BFGS                                  CG              \\\n",
       "              euclidean       inter        both   euclidean       inter   \n",
       "anchor_loss    0.000109   11.340306    0.000061    5.822015   12.106086   \n",
       "line_loss      0.000185   12.071454    0.000103    9.605169   12.787283   \n",
       "anchor_max     0.000496   13.864297    0.000112    7.745047   17.241418   \n",
       "line_max       0.000839    13.76909    0.000192   13.076488   18.455082   \n",
       "status       2222222222  2200022020  2222222222  2222222222  2200022020   \n",
       "\n",
       "                         \n",
       "                   both  \n",
       "anchor_loss    6.003193  \n",
       "line_loss      9.647818  \n",
       "anchor_max     7.729335  \n",
       "line_max      13.143444  \n",
       "status       2222222222  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MASSIVE gains from using two different z-levels for sampling euclidean\n",
    "# 5 extra 10cm above euc non-random data points\n",
    "import pandas as pd\n",
    "res = {}\n",
    "for name, sol_list in sols.items():\n",
    "    anchor_loss = np.mean([((sol.x[:4*3].reshape(4,3) - anchors)**2).mean()**(1/2) for sol in sol_list])\n",
    "    line_loss = np.mean([((sol.x[4*3:] - line_init)**2).mean()**(1/2) for sol in sol_list])\n",
    "    anchor_max = np.max([((sol.x[:4*3].reshape(4,3) - anchors)**2).mean()**(1/2) for sol in sol_list])\n",
    "    line_max = np.max([((sol.x[4*3:] - line_init)**2).mean()**(1/2) for sol in sol_list])\n",
    "    status = ''.join([str(sol.status) for sol in sol_list])\n",
    "    res[name] = {'anchor_loss': anchor_loss, 'line_loss': line_loss, 'anchor_max': anchor_max, 'line_max': line_max, 'status': status}\n",
    "pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">BFGS</th>\n",
       "      <th colspan=\"3\" halign=\"left\">CG</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>euclidean</th>\n",
       "      <th>inter</th>\n",
       "      <th>both</th>\n",
       "      <th>euclidean</th>\n",
       "      <th>inter</th>\n",
       "      <th>both</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anchor_loss</th>\n",
       "      <td>4.786648</td>\n",
       "      <td>11.109734</td>\n",
       "      <td>4.787982</td>\n",
       "      <td>6.228483</td>\n",
       "      <td>11.849605</td>\n",
       "      <td>6.103912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line_loss</th>\n",
       "      <td>8.725527</td>\n",
       "      <td>11.694716</td>\n",
       "      <td>8.727095</td>\n",
       "      <td>8.943039</td>\n",
       "      <td>12.619355</td>\n",
       "      <td>8.878411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anchor_max</th>\n",
       "      <td>23.992649</td>\n",
       "      <td>13.793859</td>\n",
       "      <td>24.025675</td>\n",
       "      <td>8.422153</td>\n",
       "      <td>21.285345</td>\n",
       "      <td>8.41668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line_max</th>\n",
       "      <td>43.685992</td>\n",
       "      <td>13.693064</td>\n",
       "      <td>43.719713</td>\n",
       "      <td>11.257996</td>\n",
       "      <td>18.011963</td>\n",
       "      <td>11.247827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>status</th>\n",
       "      <td>2222222222</td>\n",
       "      <td>2022002000</td>\n",
       "      <td>2222222222</td>\n",
       "      <td>2222222222</td>\n",
       "      <td>2022002000</td>\n",
       "      <td>2222222222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   BFGS                                  CG              \\\n",
       "              euclidean       inter        both   euclidean       inter   \n",
       "anchor_loss    4.786648   11.109734    4.787982    6.228483   11.849605   \n",
       "line_loss      8.725527   11.694716    8.727095    8.943039   12.619355   \n",
       "anchor_max    23.992649   13.793859   24.025675    8.422153   21.285345   \n",
       "line_max      43.685992   13.693064   43.719713   11.257996   18.011963   \n",
       "status       2222222222  2022002000  2222222222  2222222222  2022002000   \n",
       "\n",
       "                         \n",
       "                   both  \n",
       "anchor_loss    6.103912  \n",
       "line_loss      8.878411  \n",
       "anchor_max      8.41668  \n",
       "line_max      11.247827  \n",
       "status       2222222222  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5 extra euc non-random data points\n",
    "import pandas as pd\n",
    "res = {}\n",
    "for name, sol_list in sols.items():\n",
    "    anchor_loss = np.mean([((sol.x[:4*3].reshape(4,3) - anchors)**2).mean()**(1/2) for sol in sol_list])\n",
    "    line_loss = np.mean([((sol.x[4*3:] - line_init)**2).mean()**(1/2) for sol in sol_list])\n",
    "    anchor_max = np.max([((sol.x[:4*3].reshape(4,3) - anchors)**2).mean()**(1/2) for sol in sol_list])\n",
    "    line_max = np.max([((sol.x[4*3:] - line_init)**2).mean()**(1/2) for sol in sol_list])\n",
    "    status = ''.join([str(sol.status) for sol in sol_list])\n",
    "    res[name] = {'anchor_loss': anchor_loss, 'line_loss': line_loss, 'anchor_max': anchor_max, 'line_max': line_max, 'status': status}\n",
    "pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">BFGS</th>\n",
       "      <th colspan=\"3\" halign=\"left\">CG</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>euclidean</th>\n",
       "      <th>inter</th>\n",
       "      <th>both</th>\n",
       "      <th>euclidean</th>\n",
       "      <th>inter</th>\n",
       "      <th>both</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anchor_loss</th>\n",
       "      <td>0.000021</td>\n",
       "      <td>11.888273</td>\n",
       "      <td>2.042821</td>\n",
       "      <td>6.20161</td>\n",
       "      <td>11.896541</td>\n",
       "      <td>5.671906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line_loss</th>\n",
       "      <td>0.000033</td>\n",
       "      <td>12.452719</td>\n",
       "      <td>4.06347</td>\n",
       "      <td>7.650643</td>\n",
       "      <td>12.389943</td>\n",
       "      <td>7.711846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anchor_max</th>\n",
       "      <td>0.000074</td>\n",
       "      <td>14.785774</td>\n",
       "      <td>20.427825</td>\n",
       "      <td>8.62187</td>\n",
       "      <td>14.785774</td>\n",
       "      <td>8.669667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line_max</th>\n",
       "      <td>0.000109</td>\n",
       "      <td>13.693064</td>\n",
       "      <td>40.634081</td>\n",
       "      <td>9.551657</td>\n",
       "      <td>13.693064</td>\n",
       "      <td>9.470022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>status</th>\n",
       "      <td>2222222222</td>\n",
       "      <td>0200000002</td>\n",
       "      <td>2222222222</td>\n",
       "      <td>2222222222</td>\n",
       "      <td>0200000002</td>\n",
       "      <td>2222222222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   BFGS                                  CG              \\\n",
       "              euclidean       inter        both   euclidean       inter   \n",
       "anchor_loss    0.000021   11.888273    2.042821     6.20161   11.896541   \n",
       "line_loss      0.000033   12.452719     4.06347    7.650643   12.389943   \n",
       "anchor_max     0.000074   14.785774   20.427825     8.62187   14.785774   \n",
       "line_max       0.000109   13.693064   40.634081    9.551657   13.693064   \n",
       "status       2222222222  0200000002  2222222222  2222222222  0200000002   \n",
       "\n",
       "                         \n",
       "                   both  \n",
       "anchor_loss    5.671906  \n",
       "line_loss      7.711846  \n",
       "anchor_max     8.669667  \n",
       "line_max       9.470022  \n",
       "status       2222222222  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5 extra euc data points\n",
    "import pandas as pd\n",
    "res = {}\n",
    "for name, sol_list in sols.items():\n",
    "    anchor_loss = np.mean([((sol.x[:4*3].reshape(4,3) - anchors)**2).mean()**(1/2) for sol in sol_list])\n",
    "    line_loss = np.mean([((sol.x[4*3:] - line_init)**2).mean()**(1/2) for sol in sol_list])\n",
    "    anchor_max = np.max([((sol.x[:4*3].reshape(4,3) - anchors)**2).mean()**(1/2) for sol in sol_list])\n",
    "    line_max = np.max([((sol.x[4*3:] - line_init)**2).mean()**(1/2) for sol in sol_list])\n",
    "    status = ''.join([str(sol.status) for sol in sol_list])\n",
    "    res[name] = {'anchor_loss': anchor_loss, 'line_loss': line_loss, 'anchor_max': anchor_max, 'line_max': line_max, 'status': status}\n",
    "pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">BFGS</th>\n",
       "      <th colspan=\"3\" halign=\"left\">CG</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>euclidean</th>\n",
       "      <th>inter</th>\n",
       "      <th>both</th>\n",
       "      <th>euclidean</th>\n",
       "      <th>inter</th>\n",
       "      <th>both</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anchor_loss</th>\n",
       "      <td>0.000025</td>\n",
       "      <td>11.792511</td>\n",
       "      <td>1.9475</td>\n",
       "      <td>5.197017</td>\n",
       "      <td>12.033498</td>\n",
       "      <td>5.055432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line_loss</th>\n",
       "      <td>0.000041</td>\n",
       "      <td>11.656645</td>\n",
       "      <td>3.944773</td>\n",
       "      <td>8.19232</td>\n",
       "      <td>11.428797</td>\n",
       "      <td>8.123713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anchor_max</th>\n",
       "      <td>0.000068</td>\n",
       "      <td>14.14206</td>\n",
       "      <td>19.472617</td>\n",
       "      <td>6.911751</td>\n",
       "      <td>15.165819</td>\n",
       "      <td>6.974192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line_max</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>13.693064</td>\n",
       "      <td>39.443842</td>\n",
       "      <td>11.227904</td>\n",
       "      <td>13.693064</td>\n",
       "      <td>11.379613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>status</th>\n",
       "      <td>2222222222</td>\n",
       "      <td>0002000222</td>\n",
       "      <td>2222222222</td>\n",
       "      <td>2222222222</td>\n",
       "      <td>0002000222</td>\n",
       "      <td>2222222222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   BFGS                                  CG              \\\n",
       "              euclidean       inter        both   euclidean       inter   \n",
       "anchor_loss    0.000025   11.792511      1.9475    5.197017   12.033498   \n",
       "line_loss      0.000041   11.656645    3.944773     8.19232   11.428797   \n",
       "anchor_max     0.000068    14.14206   19.472617    6.911751   15.165819   \n",
       "line_max         0.0001   13.693064   39.443842   11.227904   13.693064   \n",
       "status       2222222222  0002000222  2222222222  2222222222  0002000222   \n",
       "\n",
       "                         \n",
       "                   both  \n",
       "anchor_loss    5.055432  \n",
       "line_loss      8.123713  \n",
       "anchor_max     6.974192  \n",
       "line_max      11.379613  \n",
       "status       2222222222  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 10 extra euc data points\n",
    "import pandas as pd\n",
    "res = {}\n",
    "for name, sol_list in sols.items():\n",
    "    anchor_loss = np.mean([((sol.x[:4*3].reshape(4,3) - anchors)**2).mean()**(1/2) for sol in sol_list])\n",
    "    line_loss = np.mean([((sol.x[4*3:] - line_init)**2).mean()**(1/2) for sol in sol_list])\n",
    "    anchor_max = np.max([((sol.x[:4*3].reshape(4,3) - anchors)**2).mean()**(1/2) for sol in sol_list])\n",
    "    line_max = np.max([((sol.x[4*3:] - line_init)**2).mean()**(1/2) for sol in sol_list])\n",
    "    status = ''.join([str(sol.status) for sol in sol_list])\n",
    "    res[name] = {'anchor_loss': anchor_loss, 'line_loss': line_loss, 'anchor_max': anchor_max, 'line_max': line_max, 'status': status}\n",
    "pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">Powell</th>\n",
       "      <th colspan=\"3\" halign=\"left\">SLSQP</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Nelder-Mead</th>\n",
       "      <th colspan=\"3\" halign=\"left\">BFGS</th>\n",
       "      <th colspan=\"3\" halign=\"left\">CG</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>euclidean</th>\n",
       "      <th>inter</th>\n",
       "      <th>both</th>\n",
       "      <th>euclidean</th>\n",
       "      <th>inter</th>\n",
       "      <th>both</th>\n",
       "      <th>euclidean</th>\n",
       "      <th>inter</th>\n",
       "      <th>both</th>\n",
       "      <th>euclidean</th>\n",
       "      <th>inter</th>\n",
       "      <th>both</th>\n",
       "      <th>euclidean</th>\n",
       "      <th>inter</th>\n",
       "      <th>both</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anchor_loss</th>\n",
       "      <td>11.787884</td>\n",
       "      <td>17.863724</td>\n",
       "      <td>12.157611</td>\n",
       "      <td>11.61201</td>\n",
       "      <td>10.881772</td>\n",
       "      <td>11.614585</td>\n",
       "      <td>15.054798</td>\n",
       "      <td>10.799138</td>\n",
       "      <td>14.187929</td>\n",
       "      <td>1.458247</td>\n",
       "      <td>11.192262</td>\n",
       "      <td>1.457034</td>\n",
       "      <td>4.071498</td>\n",
       "      <td>11.374859</td>\n",
       "      <td>4.087257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line_loss</th>\n",
       "      <td>20.34181</td>\n",
       "      <td>13.066242</td>\n",
       "      <td>20.923199</td>\n",
       "      <td>20.918459</td>\n",
       "      <td>11.920202</td>\n",
       "      <td>20.922492</td>\n",
       "      <td>24.161673</td>\n",
       "      <td>10.146246</td>\n",
       "      <td>22.890797</td>\n",
       "      <td>2.874255</td>\n",
       "      <td>11.952593</td>\n",
       "      <td>2.872626</td>\n",
       "      <td>6.959351</td>\n",
       "      <td>11.967763</td>\n",
       "      <td>6.985935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anchor_max</th>\n",
       "      <td>34.912919</td>\n",
       "      <td>42.225386</td>\n",
       "      <td>29.560119</td>\n",
       "      <td>43.331638</td>\n",
       "      <td>13.851175</td>\n",
       "      <td>43.35771</td>\n",
       "      <td>21.857299</td>\n",
       "      <td>13.195864</td>\n",
       "      <td>24.037809</td>\n",
       "      <td>14.581424</td>\n",
       "      <td>14.105108</td>\n",
       "      <td>14.569517</td>\n",
       "      <td>5.654434</td>\n",
       "      <td>14.103146</td>\n",
       "      <td>5.698619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line_max</th>\n",
       "      <td>62.088163</td>\n",
       "      <td>15.619371</td>\n",
       "      <td>53.293789</td>\n",
       "      <td>77.957122</td>\n",
       "      <td>13.693064</td>\n",
       "      <td>78.004247</td>\n",
       "      <td>37.376439</td>\n",
       "      <td>13.693064</td>\n",
       "      <td>41.119562</td>\n",
       "      <td>28.740755</td>\n",
       "      <td>13.693064</td>\n",
       "      <td>28.72486</td>\n",
       "      <td>9.667737</td>\n",
       "      <td>13.693064</td>\n",
       "      <td>9.74321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>status</th>\n",
       "      <td>0000000100</td>\n",
       "      <td>0000000000</td>\n",
       "      <td>0000100001</td>\n",
       "      <td>0909999999</td>\n",
       "      <td>0000000000</td>\n",
       "      <td>9999099999</td>\n",
       "      <td>0000000000</td>\n",
       "      <td>0000000000</td>\n",
       "      <td>0000000000</td>\n",
       "      <td>2222222222</td>\n",
       "      <td>0200222200</td>\n",
       "      <td>2222222222</td>\n",
       "      <td>2222222222</td>\n",
       "      <td>0200222200</td>\n",
       "      <td>2222222222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Powell                               SLSQP              \\\n",
       "              euclidean       inter        both   euclidean       inter   \n",
       "anchor_loss   11.787884   17.863724   12.157611    11.61201   10.881772   \n",
       "line_loss      20.34181   13.066242   20.923199   20.918459   11.920202   \n",
       "anchor_max    34.912919   42.225386   29.560119   43.331638   13.851175   \n",
       "line_max      62.088163   15.619371   53.293789   77.957122   13.693064   \n",
       "status       0000000100  0000000000  0000100001  0909999999  0000000000   \n",
       "\n",
       "                        Nelder-Mead                                BFGS  \\\n",
       "                   both   euclidean       inter        both   euclidean   \n",
       "anchor_loss   11.614585   15.054798   10.799138   14.187929    1.458247   \n",
       "line_loss     20.922492   24.161673   10.146246   22.890797    2.874255   \n",
       "anchor_max     43.35771   21.857299   13.195864   24.037809   14.581424   \n",
       "line_max      78.004247   37.376439   13.693064   41.119562   28.740755   \n",
       "status       9999099999  0000000000  0000000000  0000000000  2222222222   \n",
       "\n",
       "                                             CG                          \n",
       "                  inter        both   euclidean       inter        both  \n",
       "anchor_loss   11.192262    1.457034    4.071498   11.374859    4.087257  \n",
       "line_loss     11.952593    2.872626    6.959351   11.967763    6.985935  \n",
       "anchor_max    14.105108   14.569517    5.654434   14.103146    5.698619  \n",
       "line_max      13.693064    28.72486    9.667737   13.693064     9.74321  \n",
       "status       0200222200  2222222222  2222222222  0200222200  2222222222  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 100 extra euc data points\n",
    "import pandas as pd\n",
    "res = {}\n",
    "for name, sol_list in sols.items():\n",
    "    anchor_loss = np.mean([((sol.x[:4*3].reshape(4,3) - anchors)**2).mean()**(1/2) for sol in sol_list])\n",
    "    line_loss = np.mean([((sol.x[4*3:] - line_init)**2).mean()**(1/2) for sol in sol_list])\n",
    "    anchor_max = np.max([((sol.x[:4*3].reshape(4,3) - anchors)**2).mean()**(1/2) for sol in sol_list])\n",
    "    line_max = np.max([((sol.x[4*3:] - line_init)**2).mean()**(1/2) for sol in sol_list])\n",
    "    status = ''.join([str(sol.status) for sol in sol_list])\n",
    "    res[name] = {'anchor_loss': anchor_loss, 'line_loss': line_loss, 'anchor_max': anchor_max, 'line_max': line_max, 'status': status}\n",
    "pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">Powell</th>\n",
       "      <th colspan=\"3\" halign=\"left\">SLSQP</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Nelder-Mead</th>\n",
       "      <th colspan=\"3\" halign=\"left\">BFGS</th>\n",
       "      <th colspan=\"3\" halign=\"left\">CG</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>euclidean</th>\n",
       "      <th>inter</th>\n",
       "      <th>both</th>\n",
       "      <th>euclidean</th>\n",
       "      <th>inter</th>\n",
       "      <th>both</th>\n",
       "      <th>euclidean</th>\n",
       "      <th>inter</th>\n",
       "      <th>both</th>\n",
       "      <th>euclidean</th>\n",
       "      <th>inter</th>\n",
       "      <th>both</th>\n",
       "      <th>euclidean</th>\n",
       "      <th>inter</th>\n",
       "      <th>both</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anchor_loss</th>\n",
       "      <td>18.654866</td>\n",
       "      <td>16.48032</td>\n",
       "      <td>20.630563</td>\n",
       "      <td>29.746909</td>\n",
       "      <td>20.726336</td>\n",
       "      <td>28.579247</td>\n",
       "      <td>11.074836</td>\n",
       "      <td>13.014282</td>\n",
       "      <td>11.052235</td>\n",
       "      <td>8.934511</td>\n",
       "      <td>11.984731</td>\n",
       "      <td>11.802847</td>\n",
       "      <td>10.409172</td>\n",
       "      <td>11.94372</td>\n",
       "      <td>10.685206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line_loss</th>\n",
       "      <td>13.675645</td>\n",
       "      <td>14.417241</td>\n",
       "      <td>13.689917</td>\n",
       "      <td>52.15793</td>\n",
       "      <td>14.432158</td>\n",
       "      <td>49.086452</td>\n",
       "      <td>11.693474</td>\n",
       "      <td>9.97408</td>\n",
       "      <td>11.664373</td>\n",
       "      <td>13.124035</td>\n",
       "      <td>11.522966</td>\n",
       "      <td>19.327263</td>\n",
       "      <td>9.659414</td>\n",
       "      <td>11.403273</td>\n",
       "      <td>9.539519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>status</th>\n",
       "      <td>0000000000</td>\n",
       "      <td>0000000000</td>\n",
       "      <td>0000000000</td>\n",
       "      <td>9999999999</td>\n",
       "      <td>0000000000</td>\n",
       "      <td>9990999999</td>\n",
       "      <td>0000000000</td>\n",
       "      <td>0000000000</td>\n",
       "      <td>0000000000</td>\n",
       "      <td>2222222222</td>\n",
       "      <td>2220202200</td>\n",
       "      <td>2222222222</td>\n",
       "      <td>2222222222</td>\n",
       "      <td>2220202200</td>\n",
       "      <td>2222222222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Powell                               SLSQP              \\\n",
       "              euclidean       inter        both   euclidean       inter   \n",
       "anchor_loss   18.654866    16.48032   20.630563   29.746909   20.726336   \n",
       "line_loss     13.675645   14.417241   13.689917    52.15793   14.432158   \n",
       "status       0000000000  0000000000  0000000000  9999999999  0000000000   \n",
       "\n",
       "                        Nelder-Mead                                BFGS  \\\n",
       "                   both   euclidean       inter        both   euclidean   \n",
       "anchor_loss   28.579247   11.074836   13.014282   11.052235    8.934511   \n",
       "line_loss     49.086452   11.693474     9.97408   11.664373   13.124035   \n",
       "status       9990999999  0000000000  0000000000  0000000000  2222222222   \n",
       "\n",
       "                                             CG                          \n",
       "                  inter        both   euclidean       inter        both  \n",
       "anchor_loss   11.984731   11.802847   10.409172    11.94372   10.685206  \n",
       "line_loss     11.522966   19.327263    9.659414   11.403273    9.539519  \n",
       "status       2220202200  2222222222  2222222222  2220202200  2222222222  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "res = {}\n",
    "for name, sol_list in sols.items():\n",
    "    anchor_loss = np.mean([((sol.x[:4*3].reshape(4,3) - anchors)**2).mean()**(1/2) for sol in sol_list])\n",
    "    line_loss = np.mean([((sol.x[4*3:] - line_init)**2).mean()**(1/2) for sol in sol_list])\n",
    "    status = ''.join([str(sol.status) for sol in sol_list])\n",
    "    res[name] = {'anchor_loss': anchor_loss, 'line_loss': line_loss, 'status': status}\n",
    "pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sol1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/92/xt0q79l947bcltlw2c8gyr1h0000gn/T/ipykernel_83076/236597854.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msol1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0manchors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msol1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0manchors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'----------------------------------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msol1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mline_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msol1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline_init\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sol1' is not defined"
     ]
    }
   ],
   "source": [
    "print(sol1.x[:4*3].reshape(4,3) - anchors, '\\n', sol1.x[:4*3].reshape(4,3), '\\n',anchors)\n",
    "print('----------------------------------')\n",
    "print(sol1.x[4*3:] - line_init, '\\n', sol1.x[4*3:], '\\n', line_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inter 9.36899292870272\n",
      "euc 3014.5802290045817\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3023.9492219332847"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inter_anchor_and_euclidean(sol0.x, np.concatenate([measured_line_lengths, hat_line_lengths], axis=1),\n",
    "                           num_points, grid_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inter 6.189493883656275\n",
      "euc 8977.562060882614\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8983.75155476627"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inter_anchor_and_euclidean(sol1.x, np.concatenate([measured_line_lengths, hat_line_lengths], axis=1),\n",
    "                           num_points, grid_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2bd968df4618c3e5a97a9cd62e253bccecdc097c69a245cceb83aeb24bf2e9e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
